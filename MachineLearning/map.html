<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
   <title>Machine Larning Map(alpha) <!-- ignore --></title>
<head>
<script src="/IT_notes/map_v1.js"></script>
<link rel="stylesheet" type="text/css" href="/IT_notes/map_v1.css" />
</head>


<body>
<div groupv>
<pre zoom>
<span xsmall>External Links</span>
(Forcibly incomplete but still quite pertinent list of interesting Machine Learning Links)

- @[https://pydata.org/]
- @[https://www.reddit.com/r/MachineLearning/]
- @[https://www.datasciencecentral.com/]
  Industry's online resource for data practitioners.
  From Statistics to Analytics to Machine Learning to AI, 

- @[https://www.w3.org/wiki/Lists_of_ontologies]


- @[https://docs.python.org/3.6/library/statistics.html]
  Basic statistics module included in Python 3.4+.
  NumPy/SciPy is prefered for advanced use-cases.
  Includes functions for:
  - averages⅋"middles": 
    Arithmetic|Harmonic mean, (Low|High)Median , Mode/most-common-value
  - Measures of spread:
    (population|)standard deviation, (population|) variance


<span xsmall>Bibliography</span>
- Probability:
  Statistics, third edition, by Freedman, Pisani, and Purves,
  published by W.W. Norton, 1997.
</pre>

<pre zoom>
<span xsmall>Machine Learning Nomenclature</span>
Segmentation: Part of the pre-processing where objects of interest are "extracted"
            from background.

Feature Extraction: Process that takes-in a pattern and produces feature values.
    Number of features is virtually always chosen to be fewer than the total
    necessary to describe the complete taret of interest, and this leads to a loss
    in information.

     In acts of associate-memory, the ssytem takes-in a pattern and emits another
    pattern which is representative of a general group of patterns. It thus reduces
    the information somewhat, but rarely to the extent that pattern classification
    does. In short, because of the crucial role of a decision in pattern recognition
    information, it is fundamentally an information reduction process.

    The conceptual boundary between feature-extraction and classification is arbitrary.


Subset and SUperset problem: Formally part of ºmereologyº, the study of part/whole
    relationships. It appears as though the best classifiers try to incorporate
    as much of the input into the categorization as "makes sense" but not too much.

Risk: Total spected cost  of making a wrong classification/Decision.

<span xsmall>Probability Nomenclature</span>
(Summary of Statisticals terms that also apply to Machine learning)
ºAverageº: Rºambiguous termº for:
    - arithmetic mean, median, mode, geometric mean, weighted means, ...

ºBayesian Decision Theory:º
- Ideal case in which the probability structure underlying the categories is known perfectly.
 ºWhile not very realistic, it permits us to determine the optimal (Bayes) classifierº
 ºagainst which we can compare all other classifiers.º

ºBayes' Ruleº: Rule expressing the conditional probability of the event A given the event
    B in terms of the conditional probability of the event B given the event A
    and the unconditional probability of A:
    Unconditional probability of A == prior probability of A
                                      ^^^^^^^^^^^^^^^^^^^^^^
                                      probability assigned to A
                                      prior to observing any data.
    P(A|B) == posterior probability of A given B
              probability of A updated when fact B
              has been observed
º(Naive) Bayes Classifierº: popular for antispam filtering.
 Easy to implement, efficients and work very well in relatively smalls data.
 Naive Bayes and Text Classification I, Introduction and Theory,
 R.Raschka, Computing Research Repository (CoRR), abs/1410.5329,2014,
 @[http://arxiv.org/pdf/1410.5329v3.pdf]

ºBayes Parameter Estimation⅋ Max.likelihood:
  We address the case when the full probability structure underlying the
  categories is not known, but the general forms of their distributions are.
  Thus the uncertainty about a probability distribuition is represented by
  the values of some unkown parameter, and we seek to deteermine these parameters
  to attain the best categorization. Compares to:
  ºNon Parametric Techniquesº: We have no prior parameterized knowledge about
   the underlying probability structure.  Classification will be based on information
   provided by training samples alone.

ºBiasº: (vs Random Error)
    A measurement procedure or estimator is said to be biased if,
    on the average, it gives an answer that differs from the truth.
    The bias is the average (expected) difference between the
    measurement and the truth.

ºBimodalº: two modes.
ºBinomial Distributionº: random variable with two-value distribution
                         GUI representation: pyplot.scatter , ...
ºBinomial Distribution (n, p)º: Binomial Distribution of N trials,
                                each one with probability p of "success"

ºBivariateº: (C.f. univariate.) Having or having to do with two variables.
    For example, bivariate data are data where we
    have two measurements of each "individual." These measurements might be the
    heights and weights of a group of people (an "individual" is a person), the
    heights of fathers and sons (an "individual" is a father-son pair), the pressure
    and temperature of a fixed volume of gas (an "individual" is the volume of gas
    under a certain set of experimental conditions), etc.
   ºScatterplots, the correlation coefficient, and regression make sense for º
   ºbivariate data but not univariate data.º

ºBreakdown Pointº (of an estimator): smallest fraction of observations one must
    corrupt to make the estimator take any value one wants.

ºCategorical Variableº: (C.f. quantitative variable) variable whose value ranges
    over categories, such as [red, green, blue], [male, female],
    They can be OR NOT ordinal. Take the form of enums in computer programming
    languages.
ºCorrelationº: between two ordered lists.
    A measure of linear association between the two ordered lists.
ºCorrelation coefficientº:
    measure between −1 and +1 describing of how nearly a scatterplot falls
    on a straight line.
   ºTo compute the correlation coefficient of a list of pairs of measurementsº
   º(X,Y), first transform X and Y individually into standard units.º

ºDensity, Density Scaleº:
 - The vertical axis of a histogram has units of percent per unit of the horizontal axis.
   This is called a density scale; it measures how "dense" the observations are in
   each bin. See also probability density.
   GUI representation: pyplot.histogram , ...

ºDistributionº: of a set of numerical data is how their values are distributed over the
    real numbers.
ºEstimatorº: rule for "guessing" the value of a population
    parameter based on a random sample from the population.
    An estimator is a random variable, because its value depends on which
    particular sample is obtained, which is random.
    A canonical example of an estimator is the sample mean,
    which is an estimator of the population mean.

ºGeometric Mean.º @[https://en.wikipedia.org/wiki/Geometric_mean]
 For an entity with atributes (a1, a2, a3, ... , aN), it's defined has the
 pow  (a1 x a2 x ... xaN, 1/N).  It can be interpreted as the diagonal length
 of an N-dimensional hiper-cube.
 Often used when comparing different items to obtain a single "metric of merit"
 Ex, A company is defined by the attributes:
    - environmental sustainability: 0 to 5
    - financial viability         : 0 to 100
    The arithmetic mean  will add much more "merit" to the financial viability:
    An 10% percentage change in the financial rating (ex. 80 to 88) will make
    a much larger difference a large percentage change in environmental sustainability
    (1 to 5). The geometric mean normalizes the differently-ranged values.
    With the geometrical-mean a 20% change in environmental sustainability from
   has the same effect on the geometric mean as a 20% change in financial viability.

ºHistogramº: kind of plot that summarizes how data are distributed.
    Starting with a set of class intervals, the histogram is a set of rectangles
    ("bins") sitting on the horizontal axis. The bases of the
    rectangles are the class intervals, and their heights are
    such that their areas are proportional to the fraction of observations in the
    corresponding class intervals.

    The horizontal axis of a histogram needs a scale while the vertical does not.
    GUI representation: pyplot.histogram , ...

ºInterpolationº: Given a set of bivariate data (x, y), to
    impute a value of y corresponding to some value of x at which there is
    no measurement of y is called interpolation, if the value of x is within
    the range of the measured values of x. If the value of x is outside the
    range of measured values, imputing a corresponding value of y is called
   ºextrapolationº.

ºLinear functionº: f(x,y) is linear if:
    ( i) f( a × x ) = a×f(x),
    (ii) f( x + y ) = f(x) + f(y)

ºMean, Arithmetic meanº a list of numbers:
    sum(input_list) / len(input_list)

ºMean Squared Error (MSE)º: of an estimator of a parameter is the
    expected value of the square of the difference between the estimator and the parameter.
    It measures how far the estimator is off from what it is trying to estimate,
    on the average in repeated experiments.
    The MSE can be written in terms of the bias and SE of the estimator:
       MSE(X) = (bias(X))^2 + (SE(X))^2
ºMedianº: of a list "Middle value", smallest number such that at least half the
    numbers in the list are no greater than it.

ºNonlinear Associationº
    The relationship between two variables is nonlinear if a change in one is associated
    with a change in the other that is depends on the value of the first; that is, if
   ºthe change in the second is not simply proportional to the change in the firstº, independent of
    the value of the first variable.

ºPercentileº.
    The pth percentile of a list is the smallest number such that at least p%
    of the numbers in the list are no larger than it.

ºQuantileº.
    The Qth quantile of a list
    (0 ˂ Q ≤ 1) is the smallest number such that
    the fraction Q or more of the elements of the list are
    less than or equal to it. I.e.,
    if the list contains n numbers, the qth quantile, is the smallest number
    Q such that at least n×q elements of the list are less than or equal to Q.

ºQuantitative Variableº: (C.f. Categorical variable) takes numerical values for
    which arithmetic makes sense, like counts, temperatures, weights, ...
    typicallyºthey have units of measurementº, such as meters, kilograms,  ...
   ºDiscrete Variableº: (vs continuous variable)
    - quantitative var whose set of possible values is countable.
      Ex: ages rounded to the nearest year, ....
    - A discrete random variable is one whose ºpossible values are countableº.
      (its cumulative probability distribution function is stair-step)

ºQuartilesº(of a list of numbers): @[https://en.wikipedia.org/wiki/Quartile]
    - First cited by  Jeff Brubacker in 1879.                                                IQR
    - lower quartile(LQ): a number such that at least 1/4 of the numbers in             ├───────────┤
                          the list are no larger than it, and at least 3/4 of          ºQ1º        ºQ3º
                          the numbers in the list are no smaller than it.               ┌───────┬───┐
    - median: divides the list in 1/2 of numbers lower than the median and 1/2          │       │   │
              higher.                                                              ├────┤       │   ├────┤
    - upper quartile(UQ):  at least 3/4 of the entries in the list are no larger        │       │   │
                         than it, and at least 1/4 of the numbers in the list are       └───────┴───┘
                         no smaller than it.                                                   º^Medianº

ºRegression, Linear Regressionº
    Linear regression fits a line to a scatterplot in such a way
    as to minimize the sum of the squares of the residuals. The
    resulting regression line, together with the standard deviations of the
    two variables or their correlation coefficient, can be a
    reasonable summary of a scatterplot if the scatterplot is roughly football-shaped. In
    other cases, it is a poor summary. If we are regressing the variable Y on the variable X,
    and if Y is plotted on the vertical axis and X is plotted on the horizontal axis, the
    regression line passes through the point of averages, and has slope equal to the correlation
    coefficient times the SD of Y divided by the SD of X.
ºResidualº (of predicted value) : = mesasured_value - predicted_value
ºRoot-mean-square (RMS) of a listº:
 [e1, e2, ...] → [e1^2, e2^2, ...] → mean → square_root
Bºinput_listº       = [e1, e2, ...]
Gºinput_square_listº= [ pow(e, 2) for e in Bºinput_listº ]
Qºmean_of_squareº   = sum(Gºinput_square_listº) / len(Gºinput_square_listº)
Oºroot_mean_squareº = sqrt(Qºmean_of_squareº)
  ^^^^^^^^^^^^^^^^
  The units of RMS are the same as the units of the input_list.

 Example: [1,2,3] →                                   Mean = 2
          [1,2,3] → [1,4,9] → mean = (1+4+9)/3 = 8.0 → RMS ~ 2.83
                                                       ^^^^^^^^^^
                                                      RMS shift toward "big" values.

  Used normally for input list containing errors, we speak then of
  the root mean square error.

ºScatterplotº: 2D graphics visualizing ºbivariateº data. Ex:
  weight
       │    x
       │ x    x
       │    x
       │   x
       └──────── heights


ºScatterplot.SD lineº: line going through the point of averages.
  slope =  SD of vertical variable  divided by the SD of horizontal variable

ºStandard Deviation (SD)º of a set of numbers is the RMS of the set of
 deviations between each element of the set and the mean of the set.

ºStandard Error (SE)º of a random variable is a measure of
 how far it is likely to be from its expected value; that is,
 its scatter in repeated experiments. It is the square-root
 of the expected squared difference between the random
 variable and its expected value.
 It is analogous to the SD of a list.

ºStandard Units:º
 A variable (a set of data) is said to be in standard units if its
 mean is zero and its standard deviation is one. You transform
 a set of data into standard units by subtracting the mean from each
 element of the list, and dividing the results by the standard deviation.

 A random variable is said to be in standard units if its expected value
 is zero and its standard error is one.

ºStandardizeº: To transform into standard units.
ºstochasticº: The property of having a random probability distribution
    or pattern that may be analysed statistically but may not be predicted precisely.

ºUncorrelatedº: A set of bivariate data is uncorrelated if its correlation
    coefficient is zero.
ºUnivariateº: - vs bivariate- Having or having to do with a single variable.
    Some univariate techniques and statistics include the histogram,
    IQR, mean, median, percentiles, quantiles, and SD.

ºVariableº: In probability, refers to a numerical value or a characteristic
 that can differ from individual to individual.
 Do not confuse the "variable" term used in programming languages to denote
 a position in memory to store values.

ºVarianceº of a list is the square of the standard deviation
 of the list, that is, the average of the squares of the
 deviations of the numbers in the list from their mean.
</pre>

<pre zoom>
  <span xsmall>Who is Who</span>
  (Forcibly incomplete but still quite pertinent list of core people and companies)
  - <a href="https://en.wikipedia.org/wiki/Richard_O._Duda">Richard O. Duda</a>: Author of "Pattern Classification" Book
    <a href="https://dl.acm.org/author_page.cfm?id=81332496778">ACM Digital Library Refs</a>
  - <a href="https://en.wikipedia.org/wiki/Peter_E._Hart"  >Peter E. Hart</a>  : Author of "Pattern Classification" Book
    <a href="https://dl.acm.org/author_page.cfm?id=81100122968">ACM Digital Library Refs</a>
  - David G. Stork : Author of "Pattern Classification" Book
    <a href="https://dl.acm.org/author_page.cfm?id=81100152072">ACM Digital Library refs</a>

  - Many others ...
</pre>
<pre zoom labels="">
<span xsmall>JupyterLab IDE</span>
@[https://jupyterlab.readthedocs.io/en/stable/]
- Python IDE + Python Notebooks
- Instalation as local ºpipenv projectº:
STEP 1) Create Pipfile
  $ mkdir myProject ⅋⅋ cd  myProject
  $ vimºPipfileº
   |[[source]]
   |name = "pypi"
   |url = "https://pypi.org/simple"
   |verify_ssl = true
   |
   |[dev-packages]
   |
   |[packages]
   |scipy = "*"º
   |matplotlib = "*"º
   |scikit-learn = "*"º
   |jupyterlab = "*"º
   |pandas = "*"º
   |
   |[requires]
   |python_version = "3.7"º
    
STEP 2) Install dependencies
  $ºpipenv installº #  ← Install all packages and dependencies.

DAILY-USE)
    $ cd .../myProject
    $ºpipenv shellº   #  ← Activate environment
    $ºjupyter labº1˃jupyter.log 2˃⅋1 ⅋ # ← http://localhost:8888/lab/workspaces/
</pre>


<pre zoom labels="">
<span xsmall bgorange>MACHINE LEARNING SUMMARY</span><!-- @ma -->


╔════════════════════════════════════╗  ╔═══════════════════════╗
║MATHEMATICAL FOUNDATIONS            ║  ║Artificial Intelligence║
║- Linear Algebra                    ║  ║ ┌────────────────────┐║
║- Lagrange Optimization             ║  ║ │Machine Learning    │║
║- Probability Theory                ║  ║ │ ┌─────────────────┐│║
║- Gaussian Derivatives and Integrals║  ║ │ │Neural Networks  ││║
║- Hypothesis Testing                ║  ║ │ │ ┌──────────────┐││║
║- Information Theory                ║  ║ │ │ │Deep Learning │││║
║- Computational Complexity          ║  ║ │ │ └──────────────┘││║
║  and Optimization Problems         ║  ║ │ └─────────────────┘│║
╚════════════════════════════════════╝  ║ └────────────────────┘║
                                        ╚═══════════════════════╝

╔═══════════════════════════════════╗   ╔════════════════════════════╗
║The central aim of designing       ║   ║ALGORITHM-INDEPENDENT       ║
║a machine-learning classifier is   ║   ║MACHINE LEARNING PARAMETERS ║
║ºto suggest actions when presentedº║   ║- bias                      ║
║ºwith not-yet-seen patternsº.      ║   ║- variance                  ║
║This is the issue of generalization║   ║- degress of freedom        ║
╚═══════════════════════════════════╝   ╚════════════════════════════╝

╔══════════════════════════════════════════════════════════════════╗
║There is an overall single cost associated with our decision,     ║
║and our true task is to make a decision rule (i.e., set a decision║
║boundary) so as to minimize such a cost.                          ║
║This is the central task ofºDECISION THEORYºof which pattern      ║
║classification is (perhaps) the most important subfiled.          ║
╚══════════════════════════════════════════════════════════════════╝

╔══════════════════════════════════════════════════════════════════╗
║Classification is, at base, the task of recovering the model that ║
║generated the patterns.                                           ║
║                                                                  ║
║Becauseºperfect classification performance is often impossible,º  ║
║a more general task is toºdetermine the probabilityºfor each      ║
║of the possible categories.                                       ║
╚══════════════════════════════════════════════════════════════════╝


╔═══════════════════════════════════════════════════════════════════════════════════╗
║Learning: "Any method" that incorporates information from training samples in the  ║
║design of a classifier.  Formally, it refers to some form of algorithm for reducing║
║the error on a set of training data.                                               ║
╚═══════════════════════════════════════════════════════════════════════════════════╝
                                                                                        

 _     _____    _    ____  _   _ ___ _   _  ____      ____  _   _    _    ____  _____  
| |   | ____|  / \  |  _ \| \ | |_ _| \ | |/ ___|    |  _ \| | | |  / \  / ___|| ____|_                      OºSTEP 3)ºLEARING PROCESS
| |   |  _|   / _ \ | |_) |  \| || ||  \| | |  _     | |_) | |_| | / _ \ \___ \|  _| (_)                     Oº╔══════════════════════════════════════════╗º
| |___| |___ / ___ \|  _ ˂| |\  || || |\  | |_| |    |  __/|  _  |/ ___ \ ___) | |___ _                      Oº║ LEARNING CAN BE SEEN AS THE SPLIT OF     ║º
|_____|_____/_/   \_\_| \_\_| \_|___|_| \_|\____|    |_|   |_| |_/_/   \_\____/|_____(_)                     Oº║ THE FEATURE-SPACE IN REGIONS WHERE THE   ║º
                                                                   º(SUPERVISEDº                             Oº║ DECISION─COST IS MINIMIZED BY TUNING THE ║º
                                                                    ºLEARNINGº                               Oº║ PARAMETERS                               ║º
BºPRE-SETUP)º                           BºSTEP 1)º                  ºONLY)º                                  Oº╚══════════════════════════════════════════╝º
  ┌───────────┐→  ┌─────────┐→ ┌──────────────────────────────┐ →  ┌↓↓↓↓↓↓↓↓↓↓↓↓─────────────────────────┐  ┌───────────┐ ┌─· Percepton params
  │Sensing    │→  │Feature  │  │  DATA preprocesing           │    │known value1 │ featureA1,featureB1,..├──→NON_Trained│ │ · Matrix/es of weights
  │Measuring  │→  └Extractor│→ ├──────────────────────────────┤ →  │known value2 │ featureA2,featureB2,..│  │Classifier │ │ · Tree params
  │Collecting │→  └─────────┘→ │· Remove/Replace missing data │    │known value3 │ featureA3,featureB3,..│  │- param1   ←─┘   ─ ....
  └───────────┘...             │· Split data into  train/test │    │....                                 │  │- param2,..│
                               │· L1/L2 renormalization       │    └↑────────────────────────────────────┘  └───────────┘
                               │· Rescale                     │     │              ^        ^         ^
                               │· in/de-crease dimmensions    │     │  ºSTEP 2)ºChoose the set of featuresº forming
                               └──────────────────────────────┘     │  theºModelº or ºN─dimensional Feature─spaceºB
                                                                    │
                                                                    │
                                                          In ºREINFORCED LEARNINGº (or LEARNING-WITH-A-CRITIC)
                                                          the external supervisor (known values) is replaced with
                                                          a reward-function when calculating the function to
                                                          maximize/minimize during training.


BºSTEP 4)º MODEL EVALUATION
- Use evaluation data list to check accuracy of Predicted data vs Known Data
- Go back to STEP 3), 2) or 1) if not satified according to some metric.
 ____  ____  _____ ____ ___ ____ _____ ___ ___  _   _    ____  _   _    _    ____  _____   
|  _ \|  _ \| ____|  _ \_ _/ ___|_   _|_ _/ _ \| \ | |  |  _ \| | | |  / \  / ___|| ____|_ 
| |_) | |_) |  _| | | | | | |     | |  | | | | |  \| |  | |_) | |_| | / _ \ \___ \|  _| (_)
|  __/|  _ ˂| |___| |_| | | |___  | |  | | |_| | |\  |  |  __/|  _  |/ ___ \ ___) | |___ _ 
|_|   |_| \_\_____|____/___\____| |_| |___\___/|_| \_|  |_|   |_| |_/_/   \_\____/|_____(_)
                                                      
PREDICTION: BºSTEP 5)º
            ┌──────────┐
┌──────┐    │ TRAINED  │    "Mostly-Correct" 
│INPUT │  → │          │  →   Predicted
└──────┘    │CLASSIFIER│      Output
            └──────────┘
ºFORCIBELY INCOMPLETE BUT STILL PERTINENT COMPARATIVE MATRIXº

                 ┌─ An external "teacher" provides a category label or cost for each pattern in a training set,
                 │
                 │     ┌─ the system forms clusters or "natural groupings"
                 │     │
               ┌─v─────v───┬───────────┬────────────────────────────┬──────────────────────────────────┬─────────────────────────────┐
               │           │Predic.type│ USE─CASES                  │ POPULAR ALGORITHMS               │                             │
               │Super│Un   ├───────────┤                            │                                  │                             │
               │vised│super│Categ│Conti│                            │                                  │                             │
               │     │vised│ory  │nuos │                            │                                  │                             │
 ┌─────────────┼─────┼─────┼─────┼─────┼────────────────────────────┼──────────────────────────────────┼─────────────────────────────┤
 │Classifiers  │  X  │     │  X  │     │ Spam─Filtering             │ (MultiLayer)Percepton            │Fit curve to split different │
 │             │     │     │     │     │ Sentiment analysis         │ Adaline                          │  │     +º/º  ─    categories│
 │             │     │     │     │     │ handwritten recognition    │ Naive Bayes                      │  │+ +  º/\º                 │
 │             │     │     │     │     │ Fraud Detection            │ Decision Tree                    │  │    º/  \º─               │
 │             │     │     │     │     │                            │ Logistic Regression              │  │  +º/ºo º\º               │
 │             │     │     │     │     │                            │ K─Nearest Neighbours             │  │  º/ºo  oº\º─             │
 │             │     │     │     │     │                            │ Support Vector Machine           │  └────────────              │
 ├─────────────┼─────┼─────┼─────┼─────┼────────────────────────────┼──────────────────────────────────┼─────────────────────────────┤
 │Regression   │     │  X  │  X  │  X  │  Financial Analysis        │- Linear Regresion:               │find some functional descrip-│
 │             │     │     │     │     │                            │  find linear fun.(to input vars) │tion of the data.            │
 │             │     │     │     │     │                            │- Interpolation: Fun. is known for│Fit curve to approach        │
 │             │     │     │     │     │                            │  some range. Find fun for another││      º/·º  output data     │
 │             │     │     │     │     │                            │  range of input values.          ││    ·º/º                    │
 │             │     │     │     │     │                            │- Density estimation: Estimate    ││    º/·º                    │
 │             │     │     │     │     │                            │  density (or probability) that a ││ · º/º                      │
 │             │     │     │     │     │                            │  member of a given category will ││  º/º ·                     │
 │             │     │     │     │     │                            │  be found to have particular fea-││ º/º·                       │
 │             │     │     │     │     │                            │  tures.                          │└──────────                  │
 ├─────────────┼─────┼─────┼─────┼─────┼────────────────────────────┼──────────────────────────────────┼─────────────────────────────┤
 │Clustering   │     │  X  │     │     │  Market Segmentation       │ K─Means clustering               │ Find clusters (meaninful    │
 │             │     │     │     │     │  Image Compression         │ Mean─Shift                       │ │Bº┌─────┐º     subgroups)  │
 │             │     │     │     │     │  Labeling new data         │ DBSCAN                           │ │Bº│x x  │º                 │
 │             │     │     │     │     │  Detect abnormal behaviour │                                  │ │Bº└─────┘ºº┌────┐º         │
 │             │     │     │     │     │ Automate marketing strategy│                                  │ │Qº┌────┐º º│ y  │º         │
 │             │     │     │     │     │ ...                        │                                  │ │Qº│ z  │º º│   y│º         │
 │             │     │     │     │     │                            │                                  │ │Qº│z  z│º º└────┘º         │
 │             │     │     │     │     │                            │                                  │ │Qº└────┘º                  │
 │             │     │     │     │     │                            │                                  │ └──────────────             │
 ├─────────────┼─────┼─────┼─────┼─────┼────────────────────────────┼──────────────────────────────────┼─────────────────────────────┤
 │Dimension    │     │  X  │     │     │ Data preprocessing         │ Principal Component Analysis PCA │                             │
 │Reduction    │     │     │     │     │ Recommender systems        │ Singular Value Decomposition SVD │                             │
 │             │     │     │     │     │ Topic Modeling/doc search  │ Latent Dirichlet allocation  LDA │                             │
 │             │     │     │     │     │ Fake image analysis        │ Latent Semantic Analysis         │                             │
 │             │     │     │     │     │ Risk management            │ (LSA, pLSA,GLSA)                 │                             │
 │             │     │     │     │     │                            │ t─SNE (for visualization)        │                             │
 ├─────────────┼─────┴─────┴─────┴─────┼────────────────────────────┼──────────────────────────────────┼─────────────────────────────┤
 │Ensemble     │                       │ search systems             │ (B)oostrap A(GG)regat(ING)       │                             │
 │methods      │                       │ Computer vision            │ - Random Forest                  │                             │
 │ Bagging⅋    │                       │ Object Detection           │   (Much faster than Neu.Net)     │                             │
 │ Boosting    │                       │                            │ ── ── ── ── ── ── ── ── ── ── ── │                             │
 │             │                       │                            │ BOOSTING Algorithms              │                             │
 │             │                       │                            │ (Doesn't paralelize like BAGGING,│                             │
 │             │                       │                            │  but are more precise and still  │                             │
 │             │                       │                            │  faster than Neural Nets)        │                             │
 │             │                       │                            │  - CatBoost                      │                             │
 │             │                       │                            │  - LightGBM                      │                             │
 │             │                       │                            │  - XGBoost                       │                             │
 │             │                       │                            │  - ...                           │                             │
 ├─────────────┼─────┬─────┬─────┬─────┼────────────────────────────┼──────────────────────────────────┼─────────────────────────────┤
 │Convolutional│  X  │     │  X  │     │ Search for objects in imag-│                                  │                             │
 │Neural       │     │     │     │     │ es and videos, face recogn.│                                  │                             │
 │Network      │     │     │     │     │ generatin/enhancing images,│                                  │                             │
 │             │     │     │     │     │ ...                        │                                  │                             │
 │             │     │     │     │     │                            │                                  │                             │
 │             │     │     │     │     │                            │                                  │                             │
 │             │     │     │     │     │                            │                                  │                             │
 ├─────────────┼─────┼─────┼─────┼─────┼────────────────────────────┼──────────────────────────────────┼─────────────────────────────┤
 │Recurrent    │  X  │  X? │  X  │    X│ text translation,          │                                  │                             │
 │Neural       │     │     │     │     │ speech recognition,  .     │                                  │                             │
 │Network      │     │     │     │     │ text 2 speak,              │                                  │                             │
 │             │     │     │     │     │ ....                       │                                  │                             │
 │             │     │     │     │     │                            │                                  │                             │
 │             │     │     │     │     │                            │                                  │                             │
 └─────────────┴─────┴─────┴─────┴─────┴────────────────────────────┴──────────────────────────────────┴─────────────────────────────┘</pre>
</div>

<div groupv>

<pre zoom labels="">
<span title>Matplotlib Charts</span>
ºEXTERNAL LINKSº
User's Guide   : @[https://matplotlib.org/users/index.html] 
Git Source Code: @[https://github.com/matplotlib/matplotlib] 
     Python Lib: @[https://github.com/matplotlib/matplotlib/tree/master/lib/matplotlib]
                 @[https://github.com/matplotlib/matplotlib/blob/master/lib/matplotlib/figure.py]
                 @[https://github.com/matplotlib/matplotlib/blob/master/lib/matplotlib/axes/_axes.py]
                 @[https://github.com/matplotlib/matplotlib/blob/master/lib/matplotlib/axis.py]
                 @[https://github.com/matplotlib/matplotlib/blob/master/lib/matplotlib/container.py]

        Recipes: @[https://github.com/matplotlib/matplotlib/tree/master/examples/recipes] 
                 - common_date_problems.py
                 - create_subplots.py 
                 - fill_between_alpha.py  
                 - placing_text_boxes.py   
                 - share_axis_lims_views.py 

REF: @[https://matplotlib.org/tutorials/introductory/usage.html#sphx-glr-tutorials-introductory-usage-py]

<span xsmall>ARCHITECTURE</span>
-Everything in matplotlib is organized in a hierarchy:
 o)ºstate-machine environmentº(matplotlib.pyplot module):
 ^  simple element drawing functions like lines, images, text, current axes ,...
 │
 └─o)ºobject-oriented interfaceº
      - figure creation where the user explicitly  controls figure and axes objects.

         OºArtistº ←  When the figure is rendered, all of the artists are drawn to the canvas.
             │        Most Artists are tied to an ºAxesº; and canNOT be shared
             │        all visible elements in a figure are subclasses of it 
  ┌──────────┴──────┬───────────────────────────────┬─────┐
  │                 │                               │     │
ºFigureº 1 ←→  1+BºAxesº   1 ←───────────────→    {2,3} ºAxisº   ← RºWARN:º be aware of Axes vs Axis
   ^        ^      ^^^^                             │    ^^^^
 self._axstack    (main "plot" class)               │  - number-line-like objects.
ºnumrows    º    - takes care of the data limits    │  - set graph limits
ºnumcols    º    - primary entry point to working   │  - ticks (axis marks) + ticklabels
ºadd_subplotº      with the OO interface.           │    ^^^^^                ^^^^^^^^^^
 ....            ___________                        │    location determined  format determined
                 set_title()                        │    by a Locator         by a Formatter
                 set_xlabel()                       │
                 set_ylabel()                       │
                 ___________                        │
                 dataLim: box enclos.disply.data    │
                 viewLim: view limits in data coor. │
                             ┌──────────────────────┘
                             │
  ┌────────┬────────┬────────┴────┬─────...
 text    Line2D    Collection   Patch 

                   
RºWARN:º All of plotting functions expect input of type:
         - ºnp.arrayº
         - ºnp.ma.masked_arrayº

         np.array-'like' objects (pandas, np.matrix) must be converted first:
         Ex:
         a = pandas.DataFrame(np.random.rand(4,5), columns = list('abcde'))
         b = np.matrix([[1,2],[3,4]])
         a_asarray = a.values      #   ←  Correct input to matplotlib
         b_asarray = np.asarray(b) #   ←  Correct input to matplotlib

ºMATPLOTLIB VS PYPLOTº
- Matplotlib: whole package 
- pyplot    : module of Matplotlib (matplotlib.pyplot) with simplified API:
              - state-based MATLAB-like (vs Object Oriented based)
              - functions in this module always have a "current" figure and axes
                (created automatically on first request)
              @[https://github.com/matplotlib/matplotlib/blob/master/lib/matplotlib/pyplot.py]

- pyplot Example:
  import matplotlib.pyplot as plt        #
  import numpy as np
  from IPython.display import set_matplotlib_formats
  set_matplotlib_formats('svg')          # ← Generate SVG (Defaults to PNG)

  # Defining ranges:
  x1 = np.linspace(0,    2,   10)         # ← generates evenly spaced numbers 
                                          #   over (start/stop/number) interval . In this case
                                          #   [0.0, 0.1, 0.2, 0.4, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8]
  unused_x2 = range(0,3)                  # standard python
  unused_x3 = np.arange(2.0)              # numpy arange
   
  xpow1 = x1**2                           # ←  With (x1)numpy arrays x1**3 is prefered (and faster)
  xpow3 = [i**3 for i in x1]              # ←  With (x1)numpy arrays x1**3 is prefered (and faster)
  plt.plot(x1, x1   , label='linear'   )  # ← ºAutomatically creates the axes"1"º
  plt.plot(x1, xpow2, label='quadratic')  # ←  add additional lines to   axes"1"
  plt.plot(x1, xpow3, label='qubic'    )  # ←  add additional lines to   axes"1".
                      ^^^^^                    Each plot is assigned a new color by default
                      show in legend           (if hold is set to False, each plot clears previous one)

  plt.xlabel('x label')                   # ←  set axes"1" labels
  plt.ylabel('y label')                   # ←  "   "       " 
  plt.grid  (False)                       # ←  Don't draw grid
  plt.legend()                            # ←  Show legend
  plt.title("Simple Plot")                # ←  "   "       title
  plt.legend()                            # ←  "   "       legend
                                          #    default behavior for axes attempts
                                          #    to find the location that covers
                                          #    the fewest data points (loc='best').
                                          #    (expensive computation with big data)

┌→plt.show()                              # ← · interactive  mode(ipython+pylab):
│                                               display all figures and return to prompt.
│                                             · NON-interactive  mode:
│                                               display all figures andRºblockºuntil
│                                               figures have been closed
│      
│  plt.axis()                             # ← show current axis x/y  (-0.1, 2.1, -0.4, 8.4)
│                                         #   Used as setter allows to zoom in/out of a particular
│                                         #   view region.
│  xmin,xmax,ymin,ymax=-1, 3, -1, 10      # 
│  plt.axis([xmin,xmax,ymin,ymax])        # ← Set new x/y axis  for axes
│      
└─ Call signatures:
ºplot([x_l], y_l    , [fmt], [x2_l], y2_l        , [fmt2], ...        , **kwargs) º
ºplot([x_l], y_l    , [fmt], *                   , data=None           , **kwargs)º
       ^^^   ^^^       ^^^                        ^^^^
       list (_) of     FORMAT STRINGS             Useful for labelled data
       Coord. points  '[marker][line][color]'     Supports
                       |.      |-    |b(lue)      - python dictionary
                       |,      |--   |g(reen)     - pandas.DataFame
                       |o      |-.   |r(ed)       - structured numpy array.
                       |v      |:    |c(yan)
                       |^      |     |m(agenta)
                       |˂      |     |y(ellow)
                       |˃      |     |k(lack)     Other Parameters include:
                       |1      |     |w(hite)     - scalex, scaley : bool, optional, default: True
                       |2                           determine if the view limits are adapted to 
                       |3                           the data limits.
                       |4                           The values are passed on to `autoscale_view`.
                       |s(qure)                  
                       |p(entagon)                - **kwargs : '.Line2D' properties lik  line label 
                       |*                           (auto legends), linewidth, antialiasing, marker
                       |h(exagon1)                  face color. See Line2D class constructor for full list:
                       |H(exagon2)                  lib/matplotlib/lines.py
                       |+
                       |x
                       |D(iamond)
                       |d(iamond) 
                       ||

<img src="./matplotlib_example1.svg" style="min-width:2rem; max-width:30em" /> <img src="./matplotlib_example1_zoom.svg" style="min-width:2rem; max-width:25em" />
</pre>
<pre zoom labels="">
<span xsmall>HISTOGRAMS</span>
<img src="./matplotlib_example_histogram.svg" style="min-width:2rem; max-width:30em" /> 

<span xsmall>BAR CHARTS</span>
@[https://matplotlib.org/api/_as_gen/matplotlib.pyplot.bar.html]
matplotlib.pyplot.bar(x, height, width=0.8, bottom=None, *, align='center', data=None, **kwargs)
axis_x = range(5)
data1=[1,2,3,2,1] ; data1_yerr=[0.1,0.2,0.3,0.2,0.1]
data2=[3,2,1,2,3] ; data2_yerr=[0.3,0.2,0.1,0.2,0.3]
p1=plt.bar(x=axis_x       , height=data1, width=0.5  , color='green', yerr=data1_yerr)
p2=plt.bar(x=axis_x       , height=data2, width=0.5  , color='blue' , yerr=data2_yerr, bottom=data1)
       ^^^ ^^^^^^^^         ^^^^^^^^^^^^  ^^^^^^^^^                                    ^^^^^^^^^^^^
       |   placement of     bar data      default 0.8                                  Stack on top of
       |   bars                                                                        previous data
       barh(y=axis_y,...) for horizontal bars.
           
plt.legend((p1[0], p2[0]), ('A', 'B'))
plt.show()
<img src="./matplotlib_example_stacked_bars.svg" style="min-width:2rem; max-width:30em" /> 

<span xsmall>SCATTER PLOT</span>
@[https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html]

Useful to compare bivariate distributions.
bivariateREF = np.random.normal(0.5, 0.1, 30)
bivariateVS  = np.random.normal(0.5, 0.1, 30)
                                          ^^ 
                                          number of samples
p1=plt.scatter(bivariateREF, bivariateVS, marker="x")
plt.show()
<img src="./matplotlib_example_scatter.svg" style="min-width:2rem; max-width:30em" /> 

<span xsmall>CONTOUR PLOT</span>
@[https://matplotlib.org/api/_as_gen/matplotlib.pyplot.contour.html]
delta = 0.025
x = np.arange(-3.0, 3.0, delta)
X, Y = np.meshgrid(x, x) # coordinate vectors to  coordinate matrices from coordinate vectors.
CONTOUR1 = (X**2 + Y**2)
label_l=plt.contour(X, Y, CONTOUR1)
plt.colorbar()          # optional . Show lateral bar with ranges
plt.clabel(label_l)     # optional . Tag contours
# plt.contourf(label_l) # optional . Fill with color.
plt.show()
<img src="./matplotlib_example_contour.svg" style="min-width:2rem; max-width:30em" /> 


<span xsmall>BOXPLOT (Quartiles)</span>
@[https://matplotlib.org/api/_as_gen/matplotlib.pyplot.boxplot.html]
@[https://matplotlib.org/examples/pylab_examples/boxplot_demo.html]

v_l = np.random.randn(100)
plt.boxplot(v_l)
plt.show()
<img src="./matplotlib_example_boxplot.svg" style="min-width:2rem; max-width:30em" /> 
</span>
<hr/>
<span xsmall>TUNE PERFORMANCE</span>
(In case of "many-data points", otherwise no tunning is needed

  import matplotlib.style as mplstyle
  mplstyle.use('fast')  # ← set simplification and chunking params.
                        #   to reasonable settings to speed up 
                        #   plotting large amounts of data.
  mplstyle.use([        # Alt 2: If other styles are used, get
     'dark_background', #         sure that fast is applied last in list 
     'ggplot',          #
     'fast'])           # 

<span xsmall>TROUBLESHOOTING</span>
- matplotlib.set_loglevel(*args, **kwargs)
</pre>
</div>
<div groupv>
<pre zoom labels="">
<span xsmall TODO bgorange>Seaborn: Stat Graphs</span>
<span xsmall              > over matplotlib</span>
@[https://seaborn.pydata.org/]
- a high-level interface for drawing attractive and informative statistical graphics
  on top of matplotlib.
</pre>

<pre zoom labels="">
<span title TODO>Plotly Charts</span>
@[https://plot.ly/]
@[https://towardsdatascience.com/animated-information-graphics-4531de620ce7]
</pre>

<pre zoom labels="">
<span title TODO>d3.js Charts</span>
@[https://d3js.org/]
@[https://github.com/d3/d3]
</pre>




</div>
<div group>
    <span title>Keras</span><br/>
<div groupv>
<pre zoom labels="">
<span xsmall>External Lins</span>
@[https://keras.io/]
@[https://github.com/keras-team/keras/tree/master/examples]
@[https://keras.io/getting-started/faq/#how-can-i-use-stateful-rnns]
</pre>

<pre zoom>
<span xsmall>Summary</span>
standard flow:
 define network → compile → train
</pre>

<pre zoom>
<span xsmall>Sequential model</span>
<span xsmall>(linear stack of layers)</span>
<span xsmall>LAYER CREATION</span>
- pass list of layer instances to the constructor:

from keras.models import Sequential
from keras.layers import Dense, Activation

model = Sequential(                 # ºSTEP 1 Define layersº
 [                                  # (one input layer in this example)
    Dense(32, input_shape=(784,)),  # ← Model needs FIRST LAYER input shape.
                                    #   input shape set through 'input_dim'                 (2D layers)
                                    #                           'input_dim'r+'input_length' (3D temp layers)
                                    # 32 : 32 hidden units (layers?)
    Activation('relu'),             fixed batch size     : (stateful recurrent nets): set through 'batch_size'
    Dense(10),
    Activation('softmax'),
 ]
)
</pre>

<pre zoom>
<span xsmall>Compile (multi-class, binary, mean-sq.err,custom)</span>
+----------------------------------------------------------------------------------------------------+
|                                COMPILES ARGUMENTS                                                  |
+----------------------------------------------------------------------------------------------------+

OPTIMIZER:                      | LOSS FUNCTION:                         | LIST OF METRICS:
string-ID of existing optimizer | string-ID of existing loss funct       | string-ID
 ('rmsprop', 'adagrad',...)     | ('categorical_crossentropy', 'mse',..) |  (metrics=['accuracy'])
OR Optimizer class instance.    | OR objective function.                 | OR Custom metric function


MULTI-CLASS CLASS.PROBLEM         | BINARY CLASS.PROBLEM         | MEAN SQUARED ERROR    | # CUSTOM METRICS
model.compile(                    | model.compile(               | REGRE.PROBLEM         | import keras.backend as K
  optimizer='rmsprop',            |   optimizer='rmsprop',       | model.compile(        |
  loss='categorical_crossentropy',|   loss='binary_crossentropy',|   optimizer='rmsprop',| def mean_pred(y_true, y_pred):
  metrics=['accuracy'])           |   metrics=['accuracy'])      |   loss='mse')         |   return K.mean(y_pred)
                                                                                         |
                                                                                         | model.compile(
                                                                                         |   optimizer='rmsprop',
                                                                                         |   loss='binary_crossentropy',
                                                                                         |   metrics=['accuracy', mean_pred])
</pre>

<pre zoom>
<span xsmall>TRAINING</span>
Ex.
import numpy as np              # ← INPUT DATA/LABELS ARE NUMPY ARRAYS.
input_data = np.random.random(  # ← Dummy data (input_layer.input_dim=100)
       (1000, 100))

BINARY CLASSIFICATION PROBLEM  | MULTI-CLASS (10) Class.problem
input_labels =                 | input_labels =
  np.random.randint(           |   np.random.randint(
  2, size=(1000, 1))           |   10, size=(1000, 1))
                               |
                               | # Convert labels → cat.one-hot encoding
                               | input_one_hot_lbls =  #
                               |    keras.utils.       #
                               |     to_categorical(
                               |       labels, num_classes=10)
                               |
model.fit(                     | model.fit(            # ← train the model, (typically using 'fit')
 input_data,                   |   input_data,         #   input data
 input_labels,                 |   input_one_hot_lbls, #   input labels
 epochs=10,                    |   epochs=10,          #   10 epochs iteration
 batch_size=32                 |   batch_size=32       #   batches of 32 samples
)                              | )

</pre>
</div>
<div groupv>
<span title>Examples</span>
<pre zoom>
  <span xsmall>multilayer perceptron</span>
  <span xsmall> (mlp) for multi-class</span>
  <span xsmall>softmax c12n</span>
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD

import numpy as np                      # Generate dummy data
x_train = np.random.random((1000, 20))
y_train = keras.utils.to_categorical(
  np.random.randint(10, size=(1000, 1)),
  num_classes=10)
x_test = np.random.random((100, 20))
y_test = keras.utils.to_categorical(
  np.random.randint(10, size=(100, 1)),
   num_classes=10)

model = Sequential()
# Dense(64) is a fully-connected layer with 64 hidden units.
# in the first layer, you must specify the expected input data shape:
# here, 20-dimensional vectors.
model.add(Dense(64, activation='relu', input_dim=20))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy',
              optimizer=sgd,
              metrics=['accuracy'])

model.fit(x_train, y_train,
          epochs=20,
          batch_size=128)
score = model.evaluate(x_test, y_test, batch_size=128)
</pre>
<pre zoom>
  <span xsmall>MLP for </span>
  <span xsmall>binary c12n</span>
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout

# Generate dummy data
x_train = np.random.random((1000, 20))
y_train = np.random.randint(2, size=(1000, 1))
x_test = np.random.random((100, 20))
y_test = np.random.randint(2, size=(100, 1))

model = Sequential()
model.add(Dense(64, input_dim=20, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

model.fit(x_train, y_train,
          epochs=20,
          batch_size=128)
score = model.evaluate(x_test, y_test, batch_size=128)
</pre>

<pre zoom>
  <span xsmall>VGG-like</span>
  <span xsmall>convnet</span>
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.optimizers import SGD

# Generate dummy data
x_train = np.random.random((100, 100, 100, 3))
y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)
x_test = np.random.random((20, 100, 100, 3))
y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)

model = Sequential()
# input: 100x100 images with 3 channels → (100, 100, 3) tensors.
# this applies 32 convolution filters of size 3x3 each.
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd)

model.fit(x_train, y_train, batch_size=32, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=32)
</pre>

<pre zoom>
<span xsmall>Sequence c12n</span>
<span xsmall>with LSTM:</span>
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import Embedding
from keras.layers import LSTM

max_features = 1024

model = Sequential()
model.add(Embedding(max_features, output_dim=256))
model.add(LSTM(128))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=16, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=16)
</pre>

<pre zoom>
  <span xsmall>Sequence c12n</span>
  <span xsmall>with 1D convolutions</span>
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import Embedding
from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D

seq_length = 64

model = Sequential()
model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 100)))
model.add(Conv1D(64, 3, activation='relu'))
model.add(MaxPooling1D(3))
model.add(Conv1D(128, 3, activation='relu'))
model.add(Conv1D(128, 3, activation='relu'))
model.add(GlobalAveragePooling1D())
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=16, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=16)

Stacked LSTM for sequence classification

In this model, we stack 3 LSTM layers on top of each other, making the model
capable of learning higher-level temporal representations.

The first two LSTMs return their full output sequences, but the last one only
returns the last step in its output sequence, thus dropping the temporal
dimension (i.e. converting the input sequence into a single vector).
</pre>

<pre zoom>
  <span xsmall>stacked LSTM</span>
from keras.models import Sequential
from keras.layers import LSTM, Dense
import numpy as np

data_dim = 16
timesteps = 8
num_classes = 10

# expected input data shape: (batch_size, timesteps, data_dim)
model = Sequential()
model.add(LSTM(32, return_sequences=True,
               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32
model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32
model.add(LSTM(32))  # return a single vector of dimension 32
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

# Generate dummy training data
x_train = np.random.random((1000, timesteps, data_dim))
y_train = np.random.random((1000, num_classes))

# Generate dummy validation data
x_val = np.random.random((100, timesteps, data_dim))
y_val = np.random.random((100, num_classes))

model.fit(x_train, y_train,
          batch_size=64, epochs=5,
          validation_data=(x_val, y_val))
</pre>

<pre zoom>
<span xsmall>Same stacked LSTM</span>
<span xsmall>model rendered</span>
<span xsmall>"stateful"</span>
- Stateful recurrent model:  is one for which the internal states (memories)
   obtained after processing a batch of samples are reused as initial states for
   the samples of the next batch.
     This allows to process longer sequences while keeping computational
   complexity manageable.

You can read more about stateful RNNs in the FAQ.

from keras.models import Sequential
from keras.layers import LSTM, Dense
import numpy as np

data_dim = 16
timesteps = 8
num_classes = 10
batch_size = 32

# Expected input batch shape: (batch_size, timesteps, data_dim)
# Note that we have to provide the full batch_input_shape since the network is stateful.
# the sample of index i in batch k is the follow-up for the sample i in batch k-1.
model = Sequential()
model.add(LSTM(32, return_sequences=True, stateful=True,
               batch_input_shape=(batch_size, timesteps, data_dim)))
model.add(LSTM(32, return_sequences=True, stateful=True))
model.add(LSTM(32, stateful=True))
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

# Generate dummy training data
x_train = np.random.random((batch_size * 10, timesteps, data_dim))
y_train = np.random.random((batch_size * 10, num_classes))

# Generate dummy validation data
x_val = np.random.random((batch_size * 3, timesteps, data_dim))
y_val = np.random.random((batch_size * 3, num_classes))

model.fit(x_train, y_train,
          batch_size=batch_size, epochs=5, shuffle=False,
          validation_data=(x_val, y_val))

</pre>
</div>
<div groupv>
<span title>Tunning</span>
<pre zoom>
<a xsmall TODO href="https://keras.io/optimizers/">Usage of optimizers</a>
</pre>

<pre zoom>
<a xsmall TODO href="https://keras.io/losses/">Usage of loss functions</a>
</pre>

<pre zoom>
<a xsmall TODO href="https://keras.io/models/sequential/">The Sequential Model API</a>
</pre>

<pre zoom>
<a xsmall TODO href="https://keras.io/getting-started/functional-api-guide/">Functional API (Complex Models)</a>
- functional API is the way to go for defining complex models (multi-output models,
  directed acyclic graphs, or models with shared layers)

Ex 1: a densely-connected network
 (Sequential model is probably better for this simple case)
- tensor → layer instance → tensor

from keras.layers import Input, Dense
from keras.models import Model

inputs = Input(shape=(784,)) # ← input tensor/s
x = Dense(64, activation='relu')(inputs) # ←x: layer instances
x = Dense(64, activation='relu')(x)      # ←y: layer instances
predictions = Dense(10, activation='softmax')(x)

model = Model(inputs=inputs, outputs=predictions)
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.fit(data, labels)  # starts training

All models are callable, just like layers

With the functional API, it is easy to reuse trained models: you can treat any model as if it were a layer, by calling it on a tensor. Note that by calling a model you aren't just reusing the architecture of the model, you are also reusing its weights.

x = Input(shape=(784,))
# This works, and returns the 10-way softmax we defined above.
y = model(x)

This can allow, for instance, to quickly create models that can process sequences of inputs. You could turn an image classification model into a video classification model, in just one line.

from keras.layers import TimeDistributed

# Input tensor for sequences of 20 timesteps,
# each containing a 784-dimensional vector
input_sequences = Input(shape=(20, 784))

# This applies our previous model to every timestep in the input sequences.
# the output of the previous model was a 10-way softmax,
# so the output of the layer below will be a sequence of 20 vectors of size 10.
processed_sequences = TimeDistributed(model)(input_sequences)

Multi-input and multi-output models

Here's a good use case for the functional API: models with multiple inputs and outputs. The functional API makes it easy to manipulate a large number of intertwined datastreams.

Let's consider the following model. We seek to predict how many retweets and likes a news headline will receive on Twitter. The main input to the model will be the headline itself, as a sequence of words, but to spice things up, our model will also have an auxiliary input, receiving extra data such as the time of day when the headline was posted, etc. The model will also be supervised via two loss functions. Using the main loss function earlier in a model is a good regularization mechanism for deep models.

Here's what our model looks like:

multi-input-multi-output-graph

Let's implement it with the functional API.

The main input will receive the headline, as a sequence of integers (each integer encodes a word). The integers will be between 1 and 10,000 (a vocabulary of 10,000 words) and the sequences will be 100 words long.

from keras.layers import Input, Embedding, LSTM, Dense
from keras.models import Model

# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.
# Note that we can name any layer by passing it a "name" argument.
main_input = Input(shape=(100,), dtype='int32', name='main_input')

# This embedding layer will encode the input sequence
# into a sequence of dense 512-dimensional vectors.
x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)

# A LSTM will transform the vector sequence into a single vector,
# containing information about the entire sequence
lstm_out = LSTM(32)(x)

Here we insert the auxiliary loss, allowing the LSTM and Embedding layer to be trained smoothly even though the main loss will be much higher in the model.

auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)

At this point, we feed into the model our auxiliary input data by concatenating it with the LSTM output:

auxiliary_input = Input(shape=(5,), name='aux_input')
x = keras.layers.concatenate([lstm_out, auxiliary_input])

# We stack a deep densely-connected network on top
x = Dense(64, activation='relu')(x)
x = Dense(64, activation='relu')(x)
x = Dense(64, activation='relu')(x)

# And finally we add the main logistic regression layer
main_output = Dense(1, activation='sigmoid', name='main_output')(x)

This defines a model with two inputs and two outputs:

model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])

We compile the model and assign a weight of 0.2 to the auxiliary loss. To specify different loss_weights or loss for each different output, you can use a list or a dictionary. Here we pass a single loss as the loss argument, so the same loss will be used on all outputs.

model.compile(optimizer='rmsprop', loss='binary_crossentropy',
              loss_weights=[1., 0.2])

We can train the model by passing it lists of input arrays and target arrays:

model.fit([headline_data, additional_data], [labels, labels],
          epochs=50, batch_size=32)

Since our inputs and outputs are named (we passed them a "name" argument), we could also have compiled the model via:

model.compile(optimizer='rmsprop',
              loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},
              loss_weights={'main_output': 1., 'aux_output': 0.2})

# And trained it via:
model.fit({'main_input': headline_data, 'aux_input': additional_data},
          {'main_output': labels, 'aux_output': labels},
          epochs=50, batch_size=32)

Shared layers

Another good use for the functional API are models that use shared layers. Let's take a look at shared layers.

Let's consider a dataset of tweets. We want to build a model that can tell whether two tweets are from the same person or not (this can allow us to compare users by the similarity of their tweets, for instance).

One way to achieve this is to build a model that encodes two tweets into two vectors, concatenates the vectors and then adds a logistic regression; this outputs a probability that the two tweets share the same author. The model would then be trained on positive tweet pairs and negative tweet pairs.

Because the problem is symmetric, the mechanism that encodes the first tweet should be reused (weights and all) to encode the second tweet. Here we use a shared LSTM layer to encode the tweets.

Let's build this with the functional API. We will take as input for a tweet a binary matrix of shape (280, 256), i.e. a sequence of 280 vectors of size 256, where each dimension in the 256-dimensional vector encodes the presence/absence of a character (out of an alphabet of 256 frequent characters).

import keras
from keras.layers import Input, LSTM, Dense
from keras.models import Model

tweet_a = Input(shape=(280, 256))
tweet_b = Input(shape=(280, 256))

To share a layer across different inputs, simply instantiate the layer once, then call it on as many inputs as you want:

# This layer can take as input a matrix
# and will return a vector of size 64
shared_lstm = LSTM(64)

# When we reuse the same layer instance
# multiple times, the weights of the layer
# are also being reused
# (it is effectively ºthe sameº layer)
encoded_a = shared_lstm(tweet_a)
encoded_b = shared_lstm(tweet_b)

# We can then concatenate the two vectors:
merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=-1)

# And add a logistic regression on top
predictions = Dense(1, activation='sigmoid')(merged_vector)

# We define a trainable model linking the
# tweet inputs to the predictions
model = Model(inputs=[tweet_a, tweet_b], outputs=predictions)

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])
model.fit([data_a, data_b], labels, epochs=10)

Let's pause to take a look at how to read the shared layer's output or output shape.
The concept of layer "node"

Whenever you are calling a layer on some input, you are creating a new tensor (the output of the layer), and you are adding a "node" to the layer, linking the input tensor to the output tensor. When you are calling the same layer multiple times, that layer owns multiple nodes indexed as 0, 1, 2...

In previous versions of Keras, you could obtain the output tensor of a layer instance via layer.get_output(), or its output shape via layer.output_shape. You still can (except get_output() has been replaced by the property output). But what if a layer is connected to multiple inputs?

As long as a layer is only connected to one input, there is no confusion, and .output will return the one output of the layer:

a = Input(shape=(280, 256))

lstm = LSTM(32)
encoded_a = lstm(a)

assert lstm.output == encoded_a

Not so if the layer has multiple inputs:

a = Input(shape=(280, 256))
b = Input(shape=(280, 256))

lstm = LSTM(32)
encoded_a = lstm(a)
encoded_b = lstm(b)

lstm.output

˃˃ AttributeError: Layer lstm_1 has multiple inbound nodes,
hence the notion of "layer output" is ill-defined.
Use `get_output_at(node_index)` instead.

Okay then. The following works:

assert lstm.get_output_at(0) == encoded_a
assert lstm.get_output_at(1) == encoded_b

Simple enough, right?

The same is true for the properties input_shape and output_shape: as long as the layer has only one node, or as long as all nodes have the same input/output shape, then the notion of "layer output/input shape" is well defined, and that one shape will be returned by layer.output_shape/layer.input_shape. But if, for instance, you apply the same Conv2D layer to an input of shape (32, 32, 3), and then to an input of shape (64, 64, 3), the layer will have multiple input/output shapes, and you will have to fetch them by specifying the index of the node they belong to:

a = Input(shape=(32, 32, 3))
b = Input(shape=(64, 64, 3))

conv = Conv2D(16, (3, 3), padding='same')
conved_a = conv(a)

# Only one input so far, the following will work:
assert conv.input_shape == (None, 32, 32, 3)

conved_b = conv(b)
# now the `.input_shape` property wouldn't work, but this does:
assert conv.get_input_shape_at(0) == (None, 32, 32, 3)
assert conv.get_input_shape_at(1) == (None, 64, 64, 3)

More examples

Code examples are still the best way to get started, so here are a few more.
Inception module

For more information about the Inception architecture, see Going Deeper with Convolutions.

from keras.layers import Conv2D, MaxPooling2D, Input

input_img = Input(shape=(256, 256, 3))

tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)
tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)

tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)
tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)

tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)
tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)

output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)

Residual connection on a convolution layer

For more information about residual networks, see Deep Residual Learning for Image Recognition.

from keras.layers import Conv2D, Input

# input tensor for a 3-channel 256x256 image
x = Input(shape=(256, 256, 3))
# 3x3 conv with 3 output channels (same as input channels)
y = Conv2D(3, (3, 3), padding='same')(x)
# this returns x + y.
z = keras.layers.add([x, y])

Shared vision model

This model reuses the same image-processing module on two inputs, to classify whether two MNIST digits are the same digit or different digits.

from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten
from keras.models import Model

# First, define the vision modules
digit_input = Input(shape=(27, 27, 1))
x = Conv2D(64, (3, 3))(digit_input)
x = Conv2D(64, (3, 3))(x)
x = MaxPooling2D((2, 2))(x)
out = Flatten()(x)

vision_model = Model(digit_input, out)

# Then define the tell-digits-apart model
digit_a = Input(shape=(27, 27, 1))
digit_b = Input(shape=(27, 27, 1))

# The vision model will be shared, weights and all
out_a = vision_model(digit_a)
out_b = vision_model(digit_b)

concatenated = keras.layers.concatenate([out_a, out_b])
out = Dense(1, activation='sigmoid')(concatenated)

classification_model = Model([digit_a, digit_b], out)

Visual question answering model

This model can select the correct one-word answer when asked a natural-
language question about a picture.

It works by encoding the question into a vector, encoding the image into a
vector, concatenating the two, and training on top a logistic regression over
some vocabulary of potential answers.

from keras.layers import Conv2D, MaxPooling2D, Flatten
from keras.layers import Input, LSTM, Embedding, Dense
from keras.models import Model, Sequential

# First, let's define a vision model using a Sequential model.
# This model will encode an image into a vector.
vision_model = Sequential()
vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))
vision_model.add(Conv2D(64, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
vision_model.add(Conv2D(128, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
vision_model.add(Conv2D(256, (3, 3), activation='relu'))
vision_model.add(Conv2D(256, (3, 3), activation='relu'))
vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(Flatten())

# Now let's get a tensor with the output of our vision model:
image_input = Input(shape=(224, 224, 3))
encoded_image = vision_model(image_input)

# Next, let's define a language model to encode the question into a vector.
# Each question will be at most 100 word long,
# and we will index words as integers from 1 to 9999.
question_input = Input(shape=(100,), dtype='int32')
embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)
encoded_question = LSTM(256)(embedded_question)

# Let's concatenate the question vector and the image vector:
merged = keras.layers.concatenate([encoded_question, encoded_image])

# And let's train a logistic regression over 1000 words on top:
output = Dense(1000, activation='softmax')(merged)

# This is our final model:
vqa_model = Model(inputs=[image_input, question_input], outputs=output)

# The next stage would be training this model on actual data.

Video question answering model

Now that we have trained our image QA model, we can quickly turn it into a
video QA model. With appropriate training, you will be able to show it a
short video (e.g. 100-frame human action) and ask a natural language question
about the video (e.g. "what sport is the boy playing?" → "football").

from keras.layers import TimeDistributed

video_input = Input(shape=(100, 224, 224, 3))
# This is our video encoded via the previously trained vision_model (weights are reused)
encoded_frame_sequence = TimeDistributed(vision_model)(video_input)  # the output will be a sequence of vectors
encoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector

# This is a model-level representation of the question encoder, reusing the same weights as before:
question_encoder = Model(inputs=question_input, outputs=encoded_question)

# Let's use it to encode the question:
video_question_input = Input(shape=(100,), dtype='int32')
encoded_video_question = question_encoder(video_question_input)

# And this is our video question answering model:
merged = keras.layers.concatenate([encoded_video, encoded_video_question])
output = Dense(1000, activation='softmax')(merged)
video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)
</pre>
</div>
</div>
<div groupv>
<span title>Un-ordered</span>
<pre zoom labels="">
<span xsmall TODO>Orange GUI!!</span>
@[https://orange.biolab.si/]
- Open source machine learning and data visualization for novice and expert.
-ºInteractive data analysis workflowsºwith a large toolbox.
  Perform simple data analysis with clever data visualization. Explore 
  statistical distributions, box plots and scatter plots, or dive deeper with 
  decision trees, hierarchical clustering, heatmaps, MDS and linear projections.
  Even your multidimensional data can become sensible in 2D, especially with 
  clever attribute ranking and selections.
</pre>
</div>
</body>
</html>
<!--
___________________________
set up development environment for deep learning
(Anaconda + PIP + PyCharm + ???)
https://www.programcreek.com/2017/01/set-up-development-environment-for-deep-learning/

___________________________
https://www.programcreek.com/2013/05/collection-of-natural-language-processing-tools/
Top 8 Java Tools for Natural Language Processing
_____________________
JAVA RNN
https://www.programcreek.com/2017/07/recurrent-neural-network-example-ai-programmer-1/
https://www.programcreek.com/2017/07/build-an-ai-programmer-using-recurrent-neural-network-2/
https://www.programcreek.com/2017/07/build-an-ai-programmer-using-recurrent-neural-network-3/
https://www.programcreek.com/2017/02/different-types-of-recurrent-neural-network-structures/

_______________
https://www.programcreek.com/2017/01/how-to-select-the-right-tool-for-deep-learning/
_______________
Unsupervised:

Supervised:
___________
https://en.wikipedia.org/wiki/Kalman_filter
____________
https://github.com/wireservice/agate

agate is a Python data analysis library that is optimized for humans instead of machines. It is an alternative to numpy and pandas that solves real-world problems with readable code.

_________________
https://datanalytics.com/libro_r/
_________________
http://www.elmomentodecisivo.com/
________________
https://www.datanalytics.com/
_________________
https://www.infoq.com/presentations/algorithms-counting-reddit
____________________
https://www.infoq.com/presentations/data-ml-pipelines-stitchfix
_______________
https://ai.googleblog.com/2018/08/moving-beyond-translation-with.html
_______________
https://ai.googleblog.com/
_______________
https://ai.google/
___________________
REF: https://dzone.com/articles/consensus-clustering-via-apache-spark
    In this article, we will discuss a technique called Consensus Clustering to assess the stability
    of clusters generated by a clustering algorithm with respect to small perturbations in the data
    set. We will review a sample application built using the Apache Spark machine learning library
    to show how consensus clustering can be used with K-means, Bisecting K-means, and Gaussian
    Mixture, three distinct clustering algorithms

___________________
Ontology (Aristoteles) : http://classics.mit.edu/Aristotle/categories.1.1.html
_________________________________________
https://www.serverwatch.com/server-news/nvidia-accelerates-server-workloads-with-rapids-gpu-advances.html
!!!!
_____________________
https://www.linux.com/blog/holberton/2018/10/sourced-engine-simple-elegant-way-analyze-your-code

source{d} Engine: A Simple, Elegant Way to Analyze your Code
With the recent advances in machine learning technology, it is only a matter of time before developers can expect to run full diagnostics and information retrieval on their own source code. This can include autocompletion, auto-generated user tests, more robust linters, automated code reviews and more. I recently reviewed a new product in this sphere -- the source{d} Engine.
source{d} offers a suite of applications that uses machine learning on code to complete source code analysis and assisted code reviews. Chief among them is the source{d} Engine, now in public beta; it uses a suite of open source tools (such as Gitbase, Babelfish, and Enry) to enable large-scale source code analysis. Some key uses of the source{d} Engine include language identification, parsing code into abstract syntax trees, and performing SQL Queries on your source code such as:

    What are the top repositories in a codebase based on number of commits?

    What is the most recent commit message in a given repository?

    Who are the most prolific contributors in a repository
___________________________
https://www.eleconomista.es/empresas-finanzas/noticias/9449298/10/18/COMUNICADO-Huawei-lanza-una-plataforma-de-desarrollo-de-IA-con-ciclo-de-vida-completo-mas-rapida.html
"ModelArts es una plataforma de desarrollo de inteligencia artificial más rápida e inclusiva que cualquier otra plataforma de desarrollo de IA del mercado", dijo Zheng Yelai, vicepresidente de Huawei y presidente de la unidad de negocio Huawei Cloud. "Creemos que los desarrolladores de IA sabrán apreciar lo rápido que se inicia, completa entrenamientos e implanta modelos".

El etiquetado y la preparación de datos es un proceso largo en el desarrollo de la inteligencia artificial, y representa casi el 50% del tiempo necesario. ModelArts tiene un marco de gobernanza de datos integrado para el etiquetado y la preparación de datos durante el desarrollo de IA. El marco implementa un entrenamiento iterativo para reducir el volumen de datos que tienen que ser etiquetados manualmente, lo que aumenta por 100 la eficiencia del etiquetado y la preparación de datos.

Además, ModelArts integra diversas tecnologías de optimización, especialmente el sistema de paralelo híbrido con cascada para reducir a la mitad el entrenamiento requerido en un determinado modelo, conjunto de datos o conjunto de recursos de hardware.

La implantación de modelos de IA es un proceso complejo. Con ModelArts, los modelos de entrenamiento pueden moverse a dispositivos, la periferia y la nube con solo un clic. Los trabajos de inferencia en línea o por lotes se proporcionan a través de la nube para cumplir con los diferentes requisitos de las aplicaciones, como la implantación simultánea o distribuida.

ModelArts también incorpora varias tecnologías de IA, como el aprendizaje automático, el diseño de modelos y la configuración de parámetros para acelerar el desarrollo de la inteligencia artificial.

En términos de gestión del ciclo de vida del desarrollo de IA, ModelArts abarca la recogida de datos sin procesar, el etiquetado de datos, la creación de trabajos de entrenamiento, la selección de algoritmos, la creación de modelos y la creación de servicios de inferencia. ModelArts permite a los desarrolladores de IA compartir datos, modelos y API de inteligencia artificial.
Visión de IA

Por otra parte, HiLens consta de una plataforma de desarrollo de aplicaciones de visión con IA y de un dispositivo visual potenciado con capacidades de IA. HiLens cuenta con Skill, un nuevo concepto de desarrollo de IA. Skill consiste en un código de control y modelos entrenados en ModelArts. HiLens también es compatible con modelos entrenados en otros marcos convencionales. Las capacidades desarrolladas en HiLens pueden implantarse en cualquier dispositivo que tenga integrados los chips Ascend de IA.

El dispositivo visual HiLens se compone de una cámara inteligente compatible con inferencias. Los desarrolladores pueden usar el dispositivo HiLens para crear aplicaciones de visión e implantarlas en dispositivos y en la nube. El dispositivo visual HiLens integra el chip Ascend 310, que puede procesar 100 fotogramas por segundo y detectar caras en milisegundos. Además, los livianos contenedores integrados minimizan el uso de recursos y de ancho de banda de red, y pueden descargarse e iniciarse de forma rápida
_________________________________________
https://www.infoq.com/news/2018/11/PyTorch-Developer-Preview
_________________________________________
IA Classification:
  • Cognitive Processing (including Natural Language Processing, Computer Vision, Speech Recognition)
  • Conversasional Systems and Virtual Assistants (Question&Answering, ChatBots)
  • Machine Learning & Deep Learning
  • Reference frameworks (as IBM Watson, Microsoft Cognitive, Cognitive Services in AWS, and Google and others)
_____________________________
https://www.infoq.com/news/2018/11/Google-AI-Voice
_____________________________
______________________
Learn to clearly differentiate between the buzzwords—for example, machine learning, artificial intelligence, deep learning, data science, computer vision, and robotics. Read or listen to talks by experts on each of them. Watch this <a href="https://www.youtube.com/watch?v=tKa0zDDDaQk" target="_blank">amazing video by Brandon Rohrer</a>, an influential data scientist. Or this video about the <a href="https://www.youtube.com/watch?v=Ura_ioOcpQI" target="_blank">clear differences between various roles</a> associated with data science.
______________________
!!!
https://opensource.com/article/18/10/machine-learning-python-essential-hacks-and-tricks
Includes cheatsheets for NumPy, Pandas, Matplotlib and Seaborn, Scikit-learn
______________________

Narrow AI Taxonomy

Applications      RPA     Chatbots    Document Systems     ....


Narrow AI

      Domains   Vision    Sound   NLP      Knowledge&Reasoning   Multiagent-Systems

      IA         Machine-Learning      Genetic       Network    Robotics&Signals
                  (Deep-Learning)      Algorithms    Analysis

      Core       Planning,        Statistics and      Simulation
                 Search and       data mining
                 Optimization

      Infra     Cognitive API's     On-premises     Edge-computing    CPU/GPU/ASIC
_____________________________
https://github.com/autumnai/leaf

Open Machine Intelligence Framework for Hackers. (GPU/CPU)

Leaf is a few months old, but thanks to its architecture and Rust, it is already one of the fastest Machine Intelligence Frameworks available.

    See more Deep Neural Networks benchmarks on [Deep Learning Benchmarks][deep-learning-benchmarks-website].

Leaf is portable. Run it on CPUs, GPUs, and FPGAs, on machines with an OS, or on machines without one. Run it with OpenCL or CUDA. Credit goes to Collenchyma and Rust.


https://medium.com/@mjhirn/tensorflow-wins-89b78b29aafb

We started with the development of Leaf briefly before Google released Tensorflow. For two weeks Leaf’s hypothesis seemed unique.

Although Leaf has top-notch performance and an uniquely simple yet expressive API, it will lose against Tensorflow. Leaf’s current theoretical benefits[1] are less significant, than the benefits that Tensorflow provides[2] over the early, scientific frameworks like Torch, Caffe, Theano.

The next generation of tools, that help developers to build machine learning applications will build on Tensorflow, or more specifically on higher-level frameworks, like Keras, who abstract over multiple AI Engines[3]. Back in November, when we started, this trend was less obvious to us[4].

Now that good-enough tools, to build maintainable machine-learning applications, like Tensorflow and Keras, exist, venture capital flows more and more into companies who try to create immense value in verticals with new AI-driven applications, instead of infrastructure providers.

We wanted Leaf to become the #1 machine learning framework for developers, but it became apparent, that Leaf will not receive substantial traction outside the Rust community.

Which is why Max and I will suspend the development of Leaf and focus on new ventures.

I am staying in the space of startups and AI, working with a VC to explore a new type of early stage investment fund.

Thank you so much everyone who supported us on the way to more than 4.000 Github stars and almost into Github’s Top 1000. We are very grateful.

We will continue to give back to the community with our future projects.

[1]: Significantly easier/slimmer abstractions over computation and scheduling, first-class citizen support for CUDA/OpenCL/Rust and co., clean foundation for auto diff via dual numbers and differentiable programming, compression of neural network models.

[2]: Tensorflow and its ecosystem (incl. GCloud) provides a proven solution/process for testing, deploying and maintaining models.

[3]: E.g. Facebook is working on Flow, AutoML and Asimo, which are tools to make the creation of machine learning models even easier. If they build on Tensorflow or Torch or another framework needs to be seen.

[4]: This is why the the other frameworks will vanish or take niche positions. This includes Microsoft’s CNTK.


_____________________________
https://www.wired.com/2016/05/facebook-trying-create-ai-can-create-ai/


    Finally, Neural Networks That Actually Work

"It's almost like being the coach rather than the player," says Demis Hassabis, co-founder of DeepMind, the Google outfit behind the history-making AI that beat the world's best Go player. "You're coaxing these things, rather than directly telling them what to do."

That's why many of these companies are now trying to automate this trial and error—or at least part of it. If you automate some of the heavily lifting, the thinking goes, you can more rapidly push the latest machine learning into the hands of rank-and-file engineers—and you can give the top minds more time to focus on bigger ideas and tougher problems. This, in turn, will accelerate the progress of AI inside the Internet apps and services that you and I use every day.

In other words, for computers to get smarter faster, computers themselves must handle even more of the grunt work. The giants of the Internet are building computing systems that can test countless machine learning algorithms on behalf of their engineers, that can cycle through so many possibilities on their own. Better yet, these companies are building AI algorithms that can help build AI algorithms. No joke. Inside Facebook, engineers have designed what they like to call an "automated machine learning engineer," an artificially intelligent system that helps create artificially intelligent systems. It's a long way from perfection. But the goal is to create new AI models using as little human grunt work as possible.
Feeling the Flow

After Facebook's $104 billion IPO in 2012, Hussein Mehanna and other engineers on the Facebook ads team felt an added pressure to improve the company's ad targeting, to more precisely match ads to the hundreds of millions of people using its social network. This meant building deep neural networks and other machine learning algorithms that could make better use of the vast amounts of data Facebook collects on the characteristics and behavior of those hundreds of millions of people.

    'The more ideas you try, the better. The more data you try, the better.'

According to Mehanna, Facebook engineers had no problem generating ideas for new AI, but testing these ideas was another matter. So he and his team built a tool called Flow. "We wanted to build a machine-learning assembly line that all engineers at Facebook could use," Mehanna says. Flow is designed to help engineers build, test, and execute machine learning algorithms on a massive scale, and this includes practically any form of machine learning—a broad technology that covers all services capable of learning tasks largely on their own.

Basically, engineers could readily test an endless stream of ideas across the company's sprawling network of computer data centers. They could run all sorts of algorithmic possibilities—involving not just deep learning but other forms of AI, including logistic regression to boosted decision trees—and the results could feed still more ideas. "The more ideas you try, the better," Mehanna says. "The more data you try, the better." It also meant that engineers could readily reuse algorithms that others had built, tweaking these algorithms and applying them to other tasks.

Soon, Mehanna and his team expanded Flow for use across the entire company. Inside other teams, it could help generate algorithms that could choose the links for your Faceboook News Feed, recognize faces in photos posted to the social network, or generate audio captions for photos so that the blind can understand what's in them. It could even help the company determine what parts of the world still need access to the Internet.

With Flow, Mehanna says, Facebook trains and tests about 300,000 machine learning models each month. Whereas it once rolled a new AI model onto its social network every 60 days or so, it can now release several new models each week.
The Next Frontier

The idea is far bigger than Facebook. It's common practice across the world of deep learning. Last year, Twitter acquired a startup, WhetLab, that specializes in this kind of thing, and recently, Microsoft described how its researchers use a system to test a sea of possible AI models. Microsoft researcher Jian Sun calls it "human-assisted search."

    Engineers even built their own 'automated machine learning engineer.'

Mehanna and Facebook want to accelerate this. The company plans to eventually open source Flow, sharing it with the world at large, and according to Mehanna, outfits like LinkedIn, Uber, and Twitter are already interested in using it. Mehanna and team have also built a tool called AutoML that can remove even more of the burden from human engineers. Running atop Flow, AutoML can automatically "clean" the data needed to train neural networks and other machine learning algorithms—prepare it for testing without any human intervention—and Mehanna envisions a version that could even gather the data on its own. But more intriguingly, AutoML uses artificial intelligence to help build artificial intelligence.

As Mehana says, Facebook trains and tests about 300,000 machine learning models each month. AutoML can then use the results of these tests to train another machine learning model that can optimize the training of machine learning models. Yes, that can be a hard thing to wrap your head around. Mehanna compares it to Inception. But it works. The system can automatically chooses algorithms and parameters that are likely to work. "It can almost predict the result before the training," Mehanna says.

Inside the Facebook ads team, engineers even built that automated machine learning engineer, and this too has spread to the rest of the company. It's called Asimo, and according to Facebook, there are cases where it can automatically generate enhanced and improved incarnations of existing models—models that human engineers can then instantly deploy to the net. "It cannot yet invent a new AI algorithm," Mehanna says. "But who knows, down the road..."

It's an intriguing idea—indeed, one that has captivated science fiction writers for decades: an intelligent machine that builds itself. No, Asimo isn't quite as advanced—or as frightening—as Skynet. But it's a step toward a world where so many others, not just the field's sharpest minds, will build new AI. Some of those others won't even be human.


____________________
https://rocm.github.io/
____________________
https://course.elementsofai.com/
____________________
- Cognitive Processing (including NLP, Computer Vision, Speech Recog.)
___________________________
OpenCV Python Tutorial - Find Lanes for Self-Driving Cars (Computer Vision Basics Tutorial)
- https://www.youtube.com/watch?v=eLTLtUVuuy4
______________________________
https://www.infoq.com/news/2019/01/amazon-sustainability-datasets
__________________
https://www.infoq.com/news/2019/01/exploring-quantum-neural-nets
__________________
https://www.infoq.com/presentations/ml-research-production
__________________
https://github.com/jpmorganchase/swblocks-decisiontree
____________________
https://opensource.com/article/19/2/mycroft-voice-assistant

_______________________
Tensorflow tagged by votes questions in https://datascience.stackexchange.com/

https://datascience.stackexchange.com/questions/tagged/tensorflow?sort=votes&pageSize=15
_____________________
https://github.com/dformoso/machine-learning-mindmap
___________________________
https://serverfault.com/questions/959018/apache-tuning-for-512gb-ram
______________________
Who-is-Who:
https://www.xataka.com/inteligencia-artificial/premio-turing-para-tres-principales-responsables-actual-auge-inteligencia-artificial
________________________
Neural Network Zoo!! (perceptron, feed forward, ...):
http://www.asimovinstitute.org/neural-network-zoo/
___________________
https://stackoverflow.com/questions/20923574/whats-the-difference-between-convolutional-and-recurrent-neural-networks
_________________
https://www.infoq.com/news/2019/03/TensorFlow-Privacy
_______________________
https://www.infoq.com/news/2019/04/facebook-pytorch-biggraph
PyTorch-BigGraph: distributed system that can learn embeddings for graphs with billions of nodes.

A graph is a data structure that represents relationships (or edges) between entities (or nodes).
One challenge of using a graph as input to machine learning is that the size of the data structure
is proportional to the square of the number of entities. Using such a data structure as an input
for machine learning can lead to extremely large models. Similar problems occur in natural
language processing (NLP), and one common solution is to use an embedding as the first stage
in the model.

An embedding is a mapping from a vector space with higher dimensions to one with fewer,
that preserves some feature of the original space. NLP tasks often use a word embedding
such as word2vec; in this embedding, the coordinates for words with similar meaning are
closer to each other than to words with different meanings. Similarly, in a graph embedding,
nodes that share an edge would have coordinates closer to each other than to nodes with no
shared edge. Once an embedding is created, it can be used by machine learning tasks to
transform input data into a more compact form, making the subsequent model much simpler.
Graph embeddings often map from an original space with millions of dimensions into one
with fewer than one thousand.

However, embeddings themselves are constructed from a deep-neural-network (DNN) trained
using unsupervised learning techniques, and the large space of the input data makes that
task difficult: training takes a long time, and the DNN model has so many parameters that
they may not fit into the memory of the server performing the training.

To overcome the latter problem, PyTorch-BigGraph (PBG) divides the nodes of the graph
into multiple partitions, sized such that two partitions can fit into a machine's
memory. The edges are partitioned into "buckets", with a bucket containing the edges
that connect nodes from one partition with the nodes from another partition. Training
is performed on one bucket at a time. The training can be done on one machine, or across
multiple machines using distributed training to decrease training time.

In a paper that was presented at the recent SysML Conference, experimental results
on publicly available social graph data sets show that "PBG outperforms competing
methods," such as DeepWalk and MILE.

In addition to releasing the source code, Facebook has also published a pre-trained
model containing embeddings of the full WikiData graph. This model contains 78
million entities mapped into a 200-dimensional vector space. Facebook hopes that
their work "encourages practitioners to release and experiment with even larger data sets."
_______________________________
https://www.infoq.com/news/2019/04/Google-Document-Understanding
__________________________
https://www.infoq.com/news/2019/04/Google-ML-Kit
__________________________
https://towardsdatascience.com/no-machine-learning-is-not-just-glorified-statistics-26d3952234e3
_____________________________
DVC.org


DVC is a brainchild of a data scientist and an engineer, that was created to fill in the gaps in the ML processes tooling and evolved into a successful open source project. While working on DVC we adopt best ML practices and turn them into Git-like command line tool. DVC versions multi-gigabyte datasets and ML models, make them shareable and reproducible. The tool helps to organize a more rigorous process around datasets and the data derivatives. Your favorite cloud storage (S3, GCS, or bare metal SSH server) could be used with DVC as a data file backend.

Read the organization's project ideas for Season of Docs.

Contact: Sveta at info@dvc.org
_________________________________
https://www.infoq.com/news/2019/05/google-snorkel-drybell
____________________________
https://www.infoq.com/news/2019/05/pytorch-release-performance
____________________________
OReilly
Text Analysis for Business Analytics with Python
Extracting Insight from Text Data
Walter Paczkowski, Ph.D.
June 12, 2019
""" Unlike well-structured and organized numbers-oriented data of the pre-Internet era,
text data are highly unstructured and chaotic. Some examples include:
survey verbatim responses, call center logs, field representatives notes, customer emails,
of online chats, warranty claims, dealer technician lines, and report orders.
Yet, they are data, a structure can be imposed, and they must be analyzed to extract
useful information and insight for decision making in areas such as new product
development, customer services, and message development.
... This course will show you how to work with text data to extract meaningful insight such
as sentiments (positive and negative) about products and the company itself, opinions,
suggestions and complaints, customer misunderstandings and confusions, and competitive
and positions.
By the end of this live, hands-on, online course, you’ll understand:
- the unstructured nature of text data, including the concepts of a document and a corpus
- the issues involved in preparing text data for analysis, including data
  cleaning, the importance of stop-words, and how to deal with inconsistencies
  in spelling, grammar, and punctuation
- how to summarize text data using Text Frequency/Inverse Document Frequency (TF/IDF) weights
- the very important Singular Value Decomposition (SVD) of a document-term matrix (DTM)
- how to extract meaning from a DTM: keywords, phrases, and topics
- which Python packages are used for text analysis, and when to use each

And you’ll be able to:
- impose structure on text data
- use text analysis tools to extract keywords, phrases, and topics from text data
- take a new business text dataset and analyze it for key insights using the Python packages
- apply all of the techniques above to business problems
__________________________________________
DEBUGGING DATA SCIENCE
Hands-on applied machine learning with Python
Jonathan Dinu

 The focus will be on debugging machine learning problems that arise during
the model training process and seeing how to overcome these issues to improve
the effectiveness of the model.

What you'll learn-and how you can apply it
- Properly evaluate machine learning models with advanced metrics and diagnose learning problems.
- Improve the performance of a machine learning model through
  feature selection, data augmentation, and hyperparameter optimization.
- Walk through an end-to-end applied machine learning problem applying
  cost-sensitive learning to optimize “profit.”

https://www.oreilly.com/library/view/data-science-fundamentals/9780134660141/
https://www.oreilly.com/library/view/strata-hadoop/9781491944608/video243981.html

About Jonathan Dinu :
Jonathan Dinu is currently pursuing a Ph.D. in Computer Science at Carnegie Mellon’s Human Computer Interaction Institute (HCII) where he is working to democratize machine learning and artificial intelligence through interpretable and interactive algorithms. Previously, he co-founded Zipfian Academy (an immersive data science training program acquired by Galvanize), has taught classes at the University of San Francisco, and has built a Data Visualization MOOC with Udacity.

    In addition to his professional data science experience, he has run data science trainings for a Fortune 100 company and taught workshops at Strata, PyData, & DataWeek (among others). He first discovered his love of all things data while studying Computer Science and Physics at UC Berkeley and in a former life he worked for Alpine Data Labs developing distributed machine learning algorithms for predictive analytics on Hadoop.

___________________
https://liliputing.com/2019/05/google-assistant-is-getting-10x-faster-thanks-to-on-device-language-processing.html
_____________________
TODO: BigData classify Patchyderm
http://www.pachyderm.io/open_source.html
_________________________
https://www.infoq.com/news/2019/05/bing-nns-algorithm-open-sourced/
___________________________
https://www.infoq.com/news/2019/05/openai-sparse-transformers/
______________________________________
https://www.infoq.com/news/2019/05/google-tpu-pods-beta-available/
______________________________________
https://www.infoq.com/news/2019/05/google-tensorflow-graphics/
______________________________________
https://ignite.apache.org/features/machinelearning.html
_______________________
https://www.xataka.com/inteligencia-artificial/llevamos-anos-usando-mal-redes-neuronales-ahora-sabemos-como-hacerlas-10-veces-pequenas-perder-rendimiento
______________________
https://www.infoq.com/news/2019/04/tensorflow-chrome-dinosaur-game/
____________
https://press.aboutamazon.com/news-releases/news-release-details/aws-announces-general-availability-amazon-textract
fully managed service that uses machine learning to automatically extract text and data, including from tables and forms, in virtually any document without the need for manual review, custom code, or machine learning experience.
___________________________
https://www.infoq.com/news/2019/06/open-source-automl-tool/
__________________
https://www.infoq.com/presentations/scale-dl-petaflops/
__________________
https://www.infoq.com/presentations/scale-dl-petaflops/
________________________
https://www.infoq.com/news/2019/06/open-source-automl-tool/

ºMIT Researchers Open-Source AutoML Visualization Tool ATMSeerº
A research team from MIT, Hong Kong University, and Zhejiang University has open-sourced ATMSeer, a tool for visualizing and controlling automated machine-learning processes.
________________________________
https://github.com/EdjeElectronics/TensorFlow-Object-Detection-on-the-Raspberry-Pi
A tutorial showing how to set up TensorFlow's Object Detection API on the Raspberry Pi
________________________________
https://openai.com/blog/better-language-models/
Better Language Models
and Their Implications

We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization—all without task-specific training.
___________________________________
https://m.europapress.es/ciencia/laboratorio/noticia-algoritmos-son-capaces-descubrir-conocimiento-cientifico-oculto-20190704110622.html
_____________________________
https://www.infoq.com/news/2019/07/google-dlc-beta-release/
________________________________
Taxonomy:
https://datascience.stackexchange.com/tags
__________________________________
https://opendata.stackexchange.com/tags
__________________________________
Open Data Kit

Data collection is a key component of social good efforts ranging from polio elimination to rainforest conservation and Open Data Kit (ODK) helps thousands of organizations collect data quickly, accurately, offline, and at scale.

Read the organization's project ideas for Season of Docs.

Contact: yanokwa at opendatakit.org@gmail.com
__________________________________
https://www.infoq.com/news/2019/05/google-ai-platform/

Google has recently launched AI Platform, an end-to-end platform for developers and data scientists to build, test, and deploy machine learning models
__________________________
100$ camera, 50%+ of "NewYorkers" detected
https://www.nytimes.com/interactive/2019/04/16/opinion/facial-recognition-new-york-city.html

Relacionado:
http://www.redusers.com/noticias/investigadores-belgas-descubren-metodo-enganar-camaras-ia/

_________________________________
https://www.infoq.com/news/2019/08/Baidu-OpenSources-ERNIE/

Baidu Open-Sources ERNIE 2.0, Beats BERT in Natural Language Processing Tasks
In a recent blog post, Baidu, the Chinese search engine and e-commerce giant, announced their latest open-source, natural language understanding framework called ERNIE 2.0. They also shared recent test results, including achieving state-of-the art (SOTA) results and outperforming existing frameworks, including Google’s BERT and XLNet in 16 NLP tasks in both Chinese and English.
_______________________________
<a href="https://ml-cheatsheet.readthedocs.io">https://ml-cheatsheet.readthedocs.io</a>
__________________
https://www.infoq.com/news/2019/08/adversarial-image-dataset/

University Research Teams Open-Source Natural Adversarial Image DataSet for Computer-Vision AI

Research teams from three universities recently released a dataset called ImageNet-A, containing natural adversarial images: real-world images that are misclassified by image-recognition AI. When used as a test-set on several state-of-the-art pre-trained models, the models achieve an accuracy rate of less than 3%.
___________________________
The Lack of A Priori Distinctions Between Learing Algorithms, D.H.Wolpert (1996);
No free lunch theorems for optimization, D.H. Wolpert y W.G.Macready (1997)
_________________
McCullock-Pitts  (MCP), A Logical Calculus of the Ideas Immanet in Nervous Activity,
W.S. McCulloch  and W.Pitts, Bulletin of Mathematical Biophysics, 5(4): 115-133, 1943
________________
The Perceptron: A Perceiving and Recognizing Automaton, Frank Rosenblatt, Cornell Aeronautical Laboratory

An Adaptive "Adaline" Neuron Using Chemical "Memistors", Technical Report Number 1553-2, Bernard Widrow, Ted Hoff and others
_____________
Intro to Python Scientific Libaries
NumPy: https://sebastianraschka.com/pdf/books/dlb/appendix_f_numpy-intro.pdf
Pandas: https://pandas.pydata.org/pandas-docs/stable/10min.html
Matplotlib: http://matplotlib/users/beginner.html

_____________

scikit-earn makes use amongst others, of LIBLINEAR, a highly optimized C/C++ lib from the National Taiwan University.

http://www.csie.ntu.edu.tw/cjlin/liblinear/

SVN makes use of LIBSVN
_____
http://www.graphviz.org

________________
An algorithm for finding best matches in logarithmic Expected Time, J.H.Friedman, J.L,  Bentley, and R.A. Finkel, ACM transactions on mathematical software (TOMS), 3(3): 209-226, 1977
_________
SciKit-learn metrics:
http://scikit-learn.org/stable/modules/generated/sklearn.neigbors.DistanceMetric.html
___________________
Example training data set:

https://archive.ics.uci.edu/ml/datasets/
___________________
L1/L2 regularization:
The Elements of statistical Learning, Trevor Hastie, Robert Tibshirani and Jerome Friedman, Springer Science+Business Media, 2009
___________________
Detailed evaluations of different secuencials algorithms  can be found on:
Comparative Study of Techniques for Large-Scale Feature Selection, F.Ferri, P. Pudil, M. Hatef and J. Kittler, pages 403-413, 1994
___________________
http://scikit-learn.org/stable/modules/feature_selection.html
http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/
_________________________
A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection, Kohavi, Ron, International Joint
  Conference on Artificial Intelligence (IJCAI), 14(12): 1137-43, 1995

https://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html
https://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html
https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html

Analysis of Variance of Cross-Validation Estimators of the Generalization Error, M.Markatou, H.Tian, S.Biswas, and G.M. Hripcsak, Journal of Machine Learning Research, 6: 1127-1168, 2005

Improvements on Cross-validation: The .632+ Bootstrap Method, B. Efron and R. Tibshirani, Journal of the American Statistical Association, 92 (438): 548-560, 1997

___________________
(Model evaluation and hyper-params)
Error Estimation When Using Cross-validation for Model Selection, BMC Bioinformatics, S. Varna and R. Simon, 7(1):91, 2006
________________________
(Model evaluation and hyper-params)
List of different values acepted for the qualification :
http://scikit-learn.org/stable/modules/model_evaluation.html
_____________________
(Model evaluation and hyper-params)
http://scikit-learn.org/stable/modules/generated/skleran.metrics.precision_recall_curve.html
_____________________
(Model evaluation and hyper-params)
Synthetic Minority Over-sampling Technique, Journal of Artificial Intelligence Reseach, 16: 321-357, 2002
_______________________
(Model evaluation and hyper-params)
https://github.com/scikit-learn-contrib/imbalanced-learn
________________________
Binomial coeficient: How many different ways we can choose a subset of k elements unordered from a set of N size.
_______________________
Stacking algorithm:
http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/
http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/

________________
Chap 7
Combine different models:
- The Stregth of Weak Learnability , R. E. Schapire, Machine Learing, 5(2): 197-227, 1990

- AdaBoost: Proceedings of the Thirteenth International Conference (ICML 1996)

- Experiments with a New Boosting Algorithm, Y. Freund, R.E. Schapire and others, ICML, volume 96, 148-156, 1996

- http://www.stat.osu.edu/~dmsl/GrandPrize2009_BPC_BigChaos.pdf
- http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-starts.html
__________________

Chapter 8: Machine Learning for Sentiment Analysis

- Learning Word Vercotrs for Sentiment Analysis, A.L. Maas, R.E.Daly, P.T. Pham, D.Huang, A.Y.Ng, C.Potts
   Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:
     Human Language Technologies, pages 142-150, Portland, Oregon, USA, ACM, 2011

- http://ai.stanford.edu/~amaas/data/sentiment/ (84.1MB)

- Potter Algorithm:
  An Algorithm for suffix stripping, Martin F.Porter, Program: Electronic Library and Information Systems
   14(3): 130-137, 1980
 (Implemented by http://www.nltk.org like:
  from nltk.stem.porter import PorterStemmer
  See alternatives @ http://www.nltk.org/api/nltk.stem.html

- Influence of Word Normalization on Text Classification, Michal Toman, Roman Tesar and kael Jezek,
  Proceedings of InSciT, pages 354-358, 2006


- Hashing Vectorizer: Avoids having all data in main memory:
  https://sites.google.com/site/murmurhash/

- wrod2vec algorithm: Googl2 2013,
  Bag Of Words alternative:
  Efficient Estimation of Word Representations in Vector Space, T. Mikolov, K.Chen, G.Corrado and J.Dean
  arXiv:1301.3781, 2013
  Unsupervised algo. based on neuronal networks that tries to automatically learn the
  relation amongst words, puttins words with "similar" meanings into similar groups

  https://code.google.com/p/word2vect/

Chapter 8: *Topic Modeling*
- Latent Dirichlet Allocation (LDA)
  Very related to Bayessian inference.
  Latent Dirichlet Allocation, David M.Blei, Andrew Y.Ng, Michael I.Jordanl,
  Journal of Machine Learning Research 3, pages: 993-1022, Jan. 2003.
  - It tires to find groups of words that appears frequently in new topics.
  Implemented in sckit-learn:
  from sklearn.decomposition import LatenDirchletAllocation

___________________

Chapter 10: Regression Analysis

- Introduction to Linear Regression Analysis, Montgomery, Douglas C. Montogmery, Elizabeth A. Peck, G. Geoffrey Vining, Wiley, 2012, pages: 318-319

Training Data:
https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch10/housing.data.txt

- To represent the dispersion matrix we will use the pairplot function
from Seaborn library:
  http://standford.edu/~mwaskom/software/seaborn/

- A correlation matrix can be seen as a re-scaled version of the covariance matrix in Principal Component Analysis PCA.

  - It is a cuadratic matrix that contains the Pearson Correlation Coeficient.
    that measures the lineal dependency amongst pairs of characteristics.
    They are in the range -1 to 1. 1 for perfect correlation, 0 for no correlation

 - Ordinary Least Squares (OLS) method of adjust:  It estimates the parameters of
   the linear regresion line that minimizes the sum of vertical cuadratic-distances

   not to be confused with the Mean Square Error (MSE) used to measure the performance
   (prediction vs reality error)

 - we can also use linear ecuations:
   The Classical Linear Regression Model, Dr. Stephen Pollock
    http://www.le.ac.uk/users/dsgpl/COURSES/MESOMET/ECMETXT/06mesmet.pdf

 - Automatic Estimation of the Inlier 'Threshold in Robust Multiple Structures Fitting, R. Toldo, A.FUsiello's, Springer, 2009, Image Analysis and Processing-ICIAP 2009,
  pages 123-131


  - Overfitting methods (Regularization) popular in liner regression are:
    - Ridge Regression
    - LASSO (Least Absolute Shrinkage and Selection Operator)
    - Elastic Net.
______________________
https://github.com/rasbt/python-machine-learning-book-2nd-edition
_________________________
https://github.com/snipsco/snips-nlu
Snips NLU is a Natural Language Understanding python library that allows to parse sentences written in natural language, and extract structured information.

It’s the library that powers the NLU engine used in the Snips Console that you can use to create awesome and private-by-design voice assistants.
_____________________________
https://www.infoq.com/news/2019/09/facebook-roberta-nlp/
___________________________
https://www.infoq.com/news/2019/10/google-nlp-dataset/

Google Releases Two New NLP Dialog Datasets
____________________________
https://github.com/loredanacirstea/ai-projects
_________________________
Ace html editor:
https://stackoverflow.com/questions/15485153/enable-vim-mode-in-gist-ace-editor
ace vim mode:
https://stackoverflow.com/questions/15485153/enable-vim-mode-in-gist-ace-editor

https://ace.c9.io/#nav=production
_________________________
https://www.infoq.com/news/2019/11/alexa-genetic-deep-learning/
https://arxiv.org/abs/1908.09942
Amazon's Alexa Science researchers published a paper providing a theoretical basis for neural-network optimization. While showing that it is computationally intractable to find a perfect solution, the paper does provide a formulation, the Approximate Architecture Search Problem (a-ASP), that can be solved with genetic algorithms.

________________________
https://github.com/espnet/espnet

End-to-End Speech Processing Toolkit https://espnet.github.io/espnet/
ESPnet is an end-to-end speech processing toolkit, mainly focuses on end-to-end speech recognition and end-to-end text-to-speech. ESPnet uses chainer and pytorch as a main deep learning engine, and also follows Kaldi style data processing, feature extraction/format, and recipes to provide a complete setup for speech recognition and other speech processing experiments.

__________________________
https://brohrer.github.io/blog.html !!!!
https://www.youtube.com/user/BrandonRohrer
End-to-End Machine Learning Library

_______________________
http://pyro.ai/
Deep Universal Probabilistic Programming

https://www.datanalytics.com/2019/10/14/pyro/
Leyendo sobre si dizque PyTorch le siega la hierba debajo de los pies a TensorFlow, averigué la existencia de Pyro.

Pyro se autopresenta como Deep Universal Probabilistic Programming, pero aplicando métodos porfirianos (ya sabéis: género próximo y diferencia específica), es, o pretende ser, Stan en Python y a escala.

Aquí van mis dos primeras impresiones, basadas en una inspección superficial de los tutoriales.

En primer lugar, aunque Pyro permite usar (distintas versiones de) MCMC, parece que su especialidad es la inferencia variacional estocástica. Que parece funcionar de la siguiente manera. En el MCMC tradicional uno obtiene una muestra de la distribución (a posteriori, para los amigos) de los parámetros de interés. Eso es todo: vectores de puntos. En la inferencia variacional estocástica, uno preespecifica la forma paramétrica de la posteriori y el algoritmo calcula sus parámetros a partir de los valores simulados. Por ejemplo, uno va y dice: me da que la distribución del término independiente de mi regresión lineal va a ser normal. Entonces, Pyro responde: si es normal, la mejor media y desviación estándar que encuentro son tal y cual.

La segunda observación que me permito hacer es que la forma que adquiere la implementación de modelos en Pyro está muy alejada de la forma en que los plantearía un estadístico. Uno lee código en Stan o Jags y entiende lo que está ocurriendo: las servidumbres al lenguaje subyacente son mínimas y existe un DSL conciso que permite expresar los modelos de una manera natural. Pero no pasa así con Pyro.

De todos modos, es un gran aporte y espero que en no mucho tiempo podamos construir modelos de verdad (no, XGBoost no es de verdad) en condiciones y a escala.

________________________
https://www.infoq.com/news/2019/10/nlp-model-explanation/
AI Researchers' Open-Source Model Explanation Toolkit AllenNLP Interpret
______________________
http://people.idsia.ch/~juergen/who-invented-backpropagation.html
____________________
https://www.infoq.com/news/2019/09/waymo-machine-learning-dataset/
Waymo Shares Autonomous Vehicle Dataset for Machine Learning
__________________
https://www.cerebras.net/technology/
The world's largest chip

46,225 mm2 chip
56x larger than the biggest GPU ever made
400,000 cores
78x more cores
18 GB on-chip SRAM
3000x more on-chip memory
100 Pb/s interconnect
33,000x more bandwidth
_______________
MLflow: An Open Platform to Simplify the Machine Learning Lifecycle
______________________
http://blog.classora.com/2012/09/30/taxonomias-ontologias-y-folksonomias-que-son-y-para-que-sirven/
Taxonomías, ontologías y folksonomías... ¿qué son y para qué sirven?
________________________________
https://www.infoq.com/presentations/mlflow-databricks/
_________________________
https://www.linuxlinks.com/excellent-r-natural-language-processing-tools/
 7 Excellent R Natural Language Processing Tools
_________________________
The success of deep-learning models has been driven by the use of very large datasets, such
as ImageNet http://www.image-net.org/, with hundreds of thousands of images, and complex models
with millions of parameters. Google's BERT natural-language model https://arxiv.org/abs/1810.04805
contains 300 million parameters and is trained on nearly 3 billion words
_________________________
Spark:
https://www.infoq.com/articles/spark-application-monitoring-influxdb-grafana
_______________
https://www.infoq.com/news/2019/11/deep-learning-apache-singa/
Acceptance as a top-level project means that SINGA has passed several milestones related to software quality and community, which in theory makes the software more attractive as a solution. However, one possible barrier to adoption is that instead of building upon an existing API for modeling neural networks, such as Keras, SINGA's designers chose to implement their own. By contrast, the Horovod framework open-sourced by Uber allows developers to port existing models written for the two most popular deep-learning frameworks, TensorFlow and PyTorch. PyTorch in particular is the framework used in a majority of recent research papers.
ASF has several other top-level distributed-data processing projects that support machine-learning, including Spark and Ignite. Unlike these, SINGA is designed specifically for deep-learning's large models. ASF is also home to MXNet, a deep-learning framework similar to TensorFlow and PyTorch, which is still in incubator status. AWS touted MXNet as its framework of choice in late 2016, but MXNet still hasn't achieved widespread popularity, hovering at just under 2% in KDNugget's polls.
_______________________
https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/
Why do researchers love PyTorch?

    Simplicity. It’s similar to numpy, very pythonic, and integrates easily with the rest of the Python ecosystem. For example, you can simply throw in a pdb breakpoint anywhere into your PyTorch model and it’ll work. In TensorFlow, debugging the model requires an active session and ends up being much trickier.
        Great API. Most researchers prefer PyTorch’s API to TensorFlow’s API. This is partially because PyTorch is better designed and partially because TensorFlow has handicapped itself by switching APIs so many times (e.g. ‘layers’ -> ‘slim’ -> ‘estimators’ -> ‘tf.keras’).
            Performance. Despite the fact that PyTorch’s dynamic graphs give strictly less opportunity for optimization, there have been many anecdotal reports that PyTorch is as fast if not faster than TensorFlow. It's not clear if this is really true, but at the very least, TensorFlow hasn't gained a decisive advantage in this area.
_____________________
https://www.linkedin.com/feed/update/urn:li:activity:6614480425756782592/ ← Very good Graphical Summary !!!!!
_________________________
https://www.linkedin.com/feed/update/urn:li:activity:6536133632862576640/
_________________________
<div groupv>
<span xsmall>Spark</span>
<div>
_________________________
- We discuss simulate annealing, the Boltmann learning algorithm and other
_________________________

<pre zoom labels="">
<span xsmall>Python 4 Science</span>
@[https://www.talyarkoni.org/blog/2013/11/18/the-homogenization-of-scientific-computing-or-why-python-is-steadily-eating-other-languages-lunch/]

- NumPy/SciPy: for numerical computing
- Neurosynth, NiPy etc.: for neuroimaging data analysis
- NumPy/SciPy/pandas/statsmodels: for statistical analysis
- MatPlotLib: for plotting and visualization, except for web-based visualizations (JavaScript/d3.js);
- scikit-learn: machine learning;
                breadth of implemented algorithms
                excellent documentation
                outstanding performance
- NLTK: Natural Language Processing
- BeautifulSoup: document parsing
 Visualization:
- seaborn: Michael Waskom’s package providing very high-level
           wrappers for complex plots (ggplot2-like aesthetic)
- bokeh  : (Continuum Analytics) , "potential game-changer for web-based visualization".
           Bokeh generates static JavaScript and JSON for you
           from Python code, so  your users are magically able 
           to interact with your plots on a webpage without you 
           having to write a single line of native JS code.

- <a href="http://www.datacommunitydc.org/blog/2013/05/stepping-up-to-big-data-with-r-and-python/">Stepping up to Big Data with R and Python: A Mind Map of All the Packages You Will Ever Need</a>

<a href="https://www.xmind.net/m/WvfC/">REF</a>
+-- Basic Stack
    +-- scikits image
    +-- scikits learn
    +-- scikits statsmodels
    +-- nltk
    +-- matplotlib

+-- Newer packages                         |+-- Packages
    +-- Numba                              |    +-- PyPI
    +-- wiseRF                             |+-- Efficiency
    +-- Blaze                              |    +-- Cython
                                           |+-- Paraller
+-- Integrated Platforms                   |    +-- iPython -- ipcluster
    +-- Continuum.io                       |    +-- PP
        +-- Anaconda                       |    +-- dispy
        +-- Wakari                         |+-- GPU
    +-- PiCloud  --- Python + AWS          |    +-- NumbaPro
    +-- wise.io  -- MLaaS  -- RandomForest |    +-- PyCUDA
    +-- ipython -- Notebook                |+-- Glue
    +-- Orange                             |    +-- rpy2 -- R
                                           |    +-- PySpark -- Spark
+-- Visualization                          |    +-- ipython -- "magic" 
    +-- matplotlib                         |                   +-- R
    +-- Bokeh  -- ggplot for python        |                   +-- SQL
    +-- Mayavi                             |                   +-- matlab/octave
    +-- Nodebox                            |                   +-- IDL
    +-- igraph                             |   +-- jython -- java
    +-- pandas  -- pandas.tools.rplot      |     +-- boto   -- Amazon Web Services
    +-- Google APIs  -- goggleVis

+-- Data formats                | +-- MapReduce
    +-- Flat text               |     +-- Hadoop Interface
        +-- xreadlines          |         +-- Hadoop Streaming
        +-- readlines           |             +-- Hadoopy
        +-- pandas              |             +-- dumbo
            +-- read_csv        |             +-- mrjob
            +-- read_fwf        | 
        +-- xlrd/xlwt/xlutils   |         +-- Pydoop -- Pipes
    +-- HDF5                    |     +-- disco
        +-- PyTables
        +-- h5py
    +-- SQL
        +-- SQLAlchemy
        +-- pysqlite3
        +-- pyodbc
            +-- Vertica
            +-- Netezza
            +-- Teradata
    +-- NoSQL
        +-- MongoDB - PyMongo
        +-- CouchDB 
            +-- couchdb-python
            +-- couchdbkit
    +-- JSON
        +-- Standard Library
        +-- simplejson
    +-- XML
        +-- Standard Library
    +-- HBase
        +-- HappyBase

Web scraping:
    Scrapy: 
</pre>
_________________________
https://towardsdatascience.com/
_________________________
_________________________
https://www.infoq.com/news/2019/12/uber-ai-language-model/
Uber Open-Sources Plug-and-Play Language Model for Controlling AI-Generated Text
2 min read by Anthony Alford

Uber AI open-sourced their plug-and-play language model (PPLM) which can control
the topic and sentiment of AI-generated text. The model's output is evaluated 
by human judges as achieving 36% better topic accuracy compared to the baseline GPT-2 model.

The team provided a full description of the system and experiments in a paper 
published on arXiv. PPLM starts with a pre-trained  language model (LM), such as GPT-2. 
These LMs can produce complex output which approaches human fluency, but it is difficult 
to control the specific properties of the generated text. Instead of "fine-tuning" the LM
with additional training data, PPLM uses a separate attribute model that can evaluate the 
LM's output for sentiment or topic; this model is used to control the text produced by the 
LM. A strength parameter can tune how much the attribute model adjusts the LM output.
According to Uber's researchers,
______________________________
https://luminoth.ai/ !!! OpenSource Computer Vision Toolkit
____________________
https://pypi.org/project/click/
Composable command line interface toolkit
Click is a Python package for creating beautiful command line interfaces in a composable way with as little code as necessary. It’s the “Command Line Interface Creation Kit”. It’s highly configurable but comes with sensible defaults out of the box.
____________________
<a href="https://www.kdnuggets.com/2012/11/best-python-modules-for-data-mining.html">Best Python modules for data mining</a>
_____________________
http://pybrain.org/docs/
_____________________
http://www.datacommunitydc.org/blog/2013/05/nlp-and-big-data-using-nltk-and-hadoop-talk-overview
_____________________
pypi.python.org/pypi/MDP/2.4
_____________________
NetworkX: for graph analysis, networkx.lanl.gov/
   @[https://www.python-course.eu/networkx.php]
   - package for the creation, manipulation, and study of the structure,
     dynamics, and functions of complex networks.
   - Pygraphviz is a Python interface to the Graphviz graph layout and visualization package.
   - Python language data structures for graphs, digraphs, and multigraphs.
   - Nodes can be "anything" (e.g. text, images, XML records)
   - Edges can hold arbitrary data (e.g. weights, time-series)
   - Generators for classic graphs, random graphs, and synthetic networks
   - Standard graph algorithms
   - Network structure and analysis measures
   - Basic graph drawing
_____________________
scikits-learn - Classic machine learning algorithms 
              - Provide simple an efficient solutions
                to learning problems, scikit-learn.org/stable/ 
_____________________
https://www.datasciencecentral.com/profile/RubensZimbres
____________________
https://www.infoq.com/news/2020/01/google-albert-ai-nlp/
________________
https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.random.html
</div>

